{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1 Creating FAO forest map\n",
    "\n",
    "[Add Description]\n",
    "\n",
    "Need to create a FAO Definition Approximation following the steps from Johnson et al (2023)\n",
    "\n",
    "Steps:\n",
    "1. Data Preparation\n",
    "    1. ~~Clip the 5 GER LULC shapefiles to the Natura 2000 areas~~ (SKIP FOR NOW)\n",
    "    2. Merge the 2 required GER LULC shapefiles into 1 shapefile\n",
    "    3. vectorise the 5m JAXA FNF raster\n",
    "2. Intersect JAXA and GER LULC shapefiles\n",
    "3. Conditional Reclassing\n",
    "4. Convert to 5m raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "\n",
    "# Note: this .ipynb file depends on files & folder structures created in rq1_step1_data_prep.ipynb\n",
    "\n",
    "# Import packages\n",
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "#from osgeo import gdal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Preparation\n",
    "\n",
    "#### Step 1.1: Clip GER LULC SHPs\n",
    "\n",
    "~~In the rq1_step1_data_prep.ipynb file, I clipped all the output **rasters** to the Germany Natura 2000 areas - in this first data prep step, I do the same for the GER LULC shapefiles, as I will be working with vector data for creating the FAO-aligned forest map. ~~\n",
    "\n",
    "IMPORTANT: Skipping this clipping step for now as I didn't actually manage to clip the output rasters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIP GER LULC SHPS\n",
    "\n",
    "# Store paths to reprojected GER LULC SHPs in a list\n",
    "#ger_lulc_paths = glob.glob('./processing/clc5_class*xx_3035_DE.shp')\n",
    "\n",
    "# Create a function which which clips the shp to the Germany Natura areas (& saves to processing folder)\n",
    "#def clip_shp_to_natura(input_paths):\n",
    "#    # Load Germany Natura 2000 areas\n",
    "#    natura_de_gdf = gpd.read_file(\"./outputs/natura2000_3035_DE.shp\")\n",
    "    # Iterate through the GER LULC shp paths \n",
    "#    for path in input_paths:\n",
    "        # Open the shp for each path \n",
    "#        ger_lulc_shp = gpd.read_file(path)\n",
    "        \n",
    "        # Clip input GER LULC shp to Natura shp\n",
    "#        shp_clip  = gpd.clip(ger_lulc_shp, natura_de_gdf)\n",
    "\n",
    "        # For output file naming: extract the input file name (with extension)\n",
    "#        name_w_ext = os.path.split(path)[1] \n",
    "        # For output file naming: remove extension from input file name \n",
    "#        name_wo_ext = os.path.splitext(name_w_ext)[0]\n",
    "        # For output file naming: create the new name for clipped shp\n",
    "#        new_name = name_wo_ext + \"_clipped.shp\"\n",
    "\n",
    "        # Write the reprojected shp to the processing folder\n",
    "#        shp_clip.to_file('./processing/' + new_name)\n",
    "\n",
    "# Run the function for the German LULC zipped shps\n",
    "#clip_shp_to_natura(ger_lulc_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.2: Merge GER LULC to 1 shp \n",
    "\n",
    "In order to make the next steps easier, all the GER LULC shps can be merged into 1 master shp. \n",
    "\n",
    "Help for merging/appending shps: https://geopandas.org/en/stable/docs/user_guide/mergingdata.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ninam\\Documents\\UZH\\04_Thesis\\code\\nm_forest_thesis\\thesis_env_conda\\Lib\\site-packages\\pyogrio\\core.py:35: RuntimeWarning: Could not detect GDAL data files.  Set GDAL_DATA environment variable to the correct path.\n",
      "  _init_gdal_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CLC18                                           geometry\n",
      "1    311  POLYGON ((4344570.571 2691193.334, 4344574.302...\n",
      "2    311  POLYGON ((4344262.931 2692187.589, 4344262.643...\n",
      "3    311  POLYGON ((4339509.672 2692518.025, 4339513.666...\n",
      "4    311  POLYGON ((4341026.689 2693014.154, 4341025.65 ...\n",
      "5    311  POLYGON ((4344382.151 2693173.218, 4344386.392...\n",
      "6    311  POLYGON ((4343928.217 2694117.347, 4343931.461...\n",
      "7    311  POLYGON ((4343513.682 2694247.781, 4343520.605...\n",
      "8    311  POLYGON ((4341169.544 2694691.741, 4341192.809...\n",
      "9    311  POLYGON ((4339452.012 2694836.674, 4339482.499...\n",
      "10   311  POLYGON ((4343542.631 2694886.932, 4343549.843...\n",
      "11   311  POLYGON ((4340025.337 2695106.069, 4340029.588...\n",
      "12   311  POLYGON ((4343398.117 2695650.86, 4343401.723 ...\n",
      "13   311  POLYGON ((4341092.109 2695993.755, 4341095.105...\n",
      "14   311  POLYGON ((4342999.07 2696141.094, 4343002.811 ...\n",
      "15   311  POLYGON ((4343775.375 2696490.163, 4343775.054...\n",
      "16   311  POLYGON ((4341589.28 2696844.414, 4341590.99 2...\n",
      "17   311  POLYGON ((4342266.033 2697041.287, 4342271.404...\n",
      "18   311  POLYGON ((4328600.265 2697610.7, 4328615.805 2...\n",
      "19   311  POLYGON ((4341012.49 2697867.602, 4341010.212 ...\n"
     ]
    }
   ],
   "source": [
    "# MERGE GER LULC SHPS\n",
    "\n",
    "# Load all the GER LULC SHPs\n",
    "ger_lulc_class3_shp = gpd.read_file(\"./processing/clc5_class3xx_3035_DE.shp\")\n",
    "ger_lulc_class4_shp = gpd.read_file(\"./processing/clc5_class4xx_3035_DE.shp\")\n",
    "\n",
    "# Append the shapefiles together\n",
    "merged_ger_lulc_shp = pd.concat([ger_lulc_class3_shp,\n",
    "                                 ger_lulc_class4_shp,\n",
    "                                 ])\n",
    "\n",
    "# Check outputs\n",
    "#print(merged_ger_lulc_shp[1:20])\n",
    "\n",
    "# Write the merged output to file\n",
    "merged_ger_lulc_shp.to_file('./processing/clc5_class3_class4_3035_DE.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.3: vectorise clipped Jaxa\n",
    "\n",
    "In order to implement the workflow for creating the FAO-aligned forest map, all input data must be vectors. In this step I vectorise the clipped JAXA 5m raster.\n",
    "\n",
    "Help with raster to vector: https://py.geocompx.org/05-raster-vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POLYGONISE JAXA\n",
    "\n",
    "input2 = \"./processing/jaxa_FNF_3035_DE_5m_reclass.tif\"\n",
    "gdal_polygonize = \"./thesis_env_conda/Scripts/gdal_polygonize.exe\"\n",
    "jaxa_poly = \"./processing/jaxa_FNF_3035_DE_5m_reclass.shp\"\n",
    "\n",
    "test2 = subprocess.run([gdal_polygonize, input2, jaxa_poly],\n",
    "                     capture_output=True, \n",
    "                     text=True)\n",
    "\n",
    "print(test2.stdout)\n",
    "print(test2.stderr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
