{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1 Creating FAO forest map\n",
    "\n",
    "[Add Description]\n",
    "\n",
    "Need to create a FAO Definition Approximation following the steps from Johnson et al (2023)\n",
    "\n",
    "Steps:\n",
    "1. Create inverse raster of GER LULC Class 3 & 4\n",
    "2. Subtract inverse raster from JAXA FNF\n",
    "3. Combine clipped JAXA FNF with GER LULC FNF\n",
    "4. Copy & rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "\n",
    "# Note: this .ipynb file depends on files & folder structures created in rq1_step1_data_prep.ipynb\n",
    "\n",
    "# Import packages\n",
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "# Store gdal.exe paths\n",
    "gdal_rasterize = \"./thesis_env_conda/Library/bin/gdal_rasterize.exe\"\n",
    "gdalwarp = \"./thesis_env_conda/Library/bin/gdalwarp.exe\"\n",
    "\n",
    "# Store gdal.py paths\n",
    "gdal_calc = \"./thesis_env_conda/Lib/site-packages/GDAL-3.10.1-py3.12-win-amd64.egg-info/scripts/gdal_calc.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create inverse raster of GER LULC Class 3 & 4\n",
    "\n",
    "Originally I planned to use a vector of the GER LULC Class 3 and 4 as a clipper to extract only those areas from the JAXA FNF raster. However, this resulted in a very complex vector and the clipping process was going to be prohibitively slow. \n",
    "\n",
    "Instead I decided to rasterise the GER LULC 3 and 4 Classes and then create an inverse raster where Class 3 & 4 = 0 and everything else = 1. I can then use this inverse raster to subtract the non-class-3 and non-class-4 areas from the JAXA FNF map. \n",
    "\n",
    "Note the dissolve and explode steps are not totally needed (previously they were required for creating a clipper shp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ninam\\Documents\\UZH\\04_Thesis\\code\\nm_forest_thesis\\thesis_env_conda\\Lib\\site-packages\\pyogrio\\core.py:35: RuntimeWarning: Could not detect GDAL data files.  Set GDAL_DATA environment variable to the correct path.\n",
      "  _init_gdal_data()\n"
     ]
    }
   ],
   "source": [
    "# 1: COMBINE GER LULC SHPS\n",
    "# Takes about 12 min\n",
    "\n",
    "# Load all the GER LULC SHPs (with no columns - these are not needed)\n",
    "ger_lulc_class3_shp = gpd.read_file(\"./processing/clc5_class3xx_3035_DE.shp\", columns = [\"\"])\n",
    "ger_lulc_class4_shp = gpd.read_file(\"./processing/clc5_class4xx_3035_DE.shp\", columns = [\"\"])\n",
    "\n",
    "# Append the shapefiles together\n",
    "merged_ger_lulc_shp = pd.concat([ger_lulc_class3_shp,\n",
    "                                 ger_lulc_class4_shp,\n",
    "                                 ])\n",
    "\n",
    "# Dissolve the geometries (this creates one multi-part geometry)\n",
    "dissolved_ger_lulc_shp = merged_ger_lulc_shp.dissolve()\n",
    "\n",
    "# Explode the multi-part geometry into multiple single geometries\n",
    "exploded_ger_lulc_shp = dissolved_ger_lulc_shp.explode()\n",
    "\n",
    "# Write the merged, dissolved & exploded output to file\n",
    "exploded_ger_lulc_shp.to_file('./processing/clc5_class3_class4_3035_DE.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: INVERSE RASTERISATION\n",
    "\n",
    "# Store path to shp for rasterising\n",
    "gerlulc_3_4_shp = \"./processing/clc5_class3_class4_3035_DE.shp\"\n",
    "\n",
    "# Store path/filename for inverse rasterised output\n",
    "gerlulc_3_4_inverse = \"./processing/clc5_class3_class4_3035_DE_5m_inverse.tif\"\n",
    "\n",
    "# Run gdal_rasterize to create inverse GER LULC Class 3 & 4 raster\n",
    "# '-i' flag: invert rasterisation (burn value is burned into all parts NOT inside the polygons)\n",
    "inverse_rasterise = subprocess.run([gdal_rasterize, \n",
    "                                    '-l', 'clc5_class3_class4_3035_DE',\n",
    "                                    '-burn', '1',\n",
    "                                    '-i',    \n",
    "                                    '-tr', '5', '5',\n",
    "                                    '-a_nodata', '-9999', \n",
    "                                    '-ot', 'Int16', \n",
    "                                    '-of', 'GTiff',\n",
    "                                    '-co', 'COMPRESS=LZW', \n",
    "                                    '-co', 'BIGTIFF=YES', \n",
    "                                    gerlulc_3_4_shp,\n",
    "                                    gerlulc_3_4_inverse\n",
    "                                    ],\n",
    "                                    capture_output=True, \n",
    "                                    text=True)\n",
    "\n",
    "print(inverse_rasterise.stdout)\n",
    "print(inverse_rasterise.stderr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Subtract inverse raster from JAXA FNF\n",
    "\n",
    "Using the inverse raster from step 1, the next step is to adjust the JAXA FNF map so that all non-class-3 and non-class-4 forests are removed. Essentially, this removes any areas of forest in the JAXA map which are in predominantly agricultural or urban areas.\n",
    "\n",
    "Before I subtract the two layers, the extents will need to match - so here I follow a similar process as in \"rq1_step1_data_prep.ipynb\" to clip and adjust the extents of the inverse raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: CLIP TO CORINE BBOX\n",
    "\n",
    "# Store path to CORINE bbox shp (created in \"rq1_step1_data_prep.ipynb\")\n",
    "corine_bbox_shp = \"./processing/corine_reclass_bbox.shp\"\n",
    "\n",
    "# Define function that clips tifs to the CORINE bbox (copy from \"rq1_step1_data_prep.ipynb\")\n",
    "def bbox_clip(input_paths):\n",
    "    # Iterate through the paths \n",
    "    for path in input_paths:\n",
    "        # For output file naming: extract the input file name (with extension)\n",
    "        name_w_ext = os.path.split(path)[1] \n",
    "        # For output file naming: remove extension\n",
    "        root_name = name_w_ext[:-4]\n",
    "        # For output file naming: assemble the new file path for the output\n",
    "        output_path = \"./processing/\" + root_name + \"_bboxclip.tif\"\n",
    "\n",
    "        # Run warp to crop to the CORINE bbox\n",
    "        clip_to_bbox = subprocess.run([gdalwarp, \n",
    "                                       '-crop_to_cutline', \n",
    "                                       '-cutline', corine_bbox_shp, \n",
    "                                       '-tr', '5', '5',\n",
    "                                       '-dstnodata', '-9999', \n",
    "                                       '-ot', 'Int16', \n",
    "                                       '-co', 'COMPRESS=LZW', \n",
    "                                       '-co', 'BIGTIFF=YES', \n",
    "                                       path, \n",
    "                                       output_path\n",
    "                                       ],\n",
    "                                       capture_output=True, \n",
    "                                       text=True)\n",
    "        print(clip_to_bbox.stdout)\n",
    "        print(clip_to_bbox.stderr)\n",
    "\n",
    "# Run just for the single raster\n",
    "bbox_clip([\"./processing/clc5_class3_class4_3035_DE_5m_inverse.tif\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: WARP EXTENTS\n",
    "\n",
    "# First, extract the extents from the CORINE data (created in \"rq1_step1_data_prep.ipynb\")\n",
    "corine_ref = rasterio.open(\"./processing/U2018_CLC2018_V2020_3035_DE_5m_bboxclip.tif\")\n",
    "corine_bounds  = corine_ref.bounds\n",
    "\n",
    "# Store the bounds in the format required for gdalwarp\n",
    "corine_xmin = str(corine_bounds[0])       # xmin = left\n",
    "corine_ymin = str(corine_bounds[1])       # ymin = bottom\n",
    "corine_xmax = str(corine_bounds[2])       # xmax = right\n",
    "corine_ymax = str(corine_bounds[3])       # ymax = top\n",
    "\n",
    "\n",
    "# Define function that warps rasters to the CORINE extents (copy from \"rq1_step1_data_prep.ipynb\")\n",
    "def corine_warp(input_paths):\n",
    "    # Iterate through the paths \n",
    "    for path in input_paths:\n",
    "        # For output file naming: extract the input file name (with extension)\n",
    "        name_w_ext = os.path.split(path)[1] \n",
    "        # For output file naming: remove extension from input file name\n",
    "        name_wo_ext = os.path.splitext(name_w_ext)[0]\n",
    "        # For output file naming: assemble the new file path for the output\n",
    "        output_path = \"./processing/\" + name_wo_ext + \"_warp_exts.tif\"\n",
    "        \n",
    "        # Run warp to match all rasters to CORINE extents\n",
    "        warp_extents = subprocess.run([gdalwarp, \n",
    "                                      '-t_srs', 'EPSG:3035', \n",
    "                                      #'-tr', '5', '5',\n",
    "                                      '-te', corine_xmin, corine_ymin, corine_xmax, corine_ymax,\n",
    "                                      #'-tap',\n",
    "                                      '-ot', 'Int16', \n",
    "                                      '-co', 'COMPRESS=LZW', \n",
    "                                      '-co', 'BIGTIFF=YES', \n",
    "                                      path, \n",
    "                                      output_path\n",
    "                                      ],\n",
    "                                      capture_output=True, \n",
    "                                      text=True)\n",
    "        print(warp_extents.stdout)\n",
    "        print(warp_extents.stderr)\n",
    "\n",
    "\n",
    "# Separate Hansen processing\n",
    "corine_warp([\"./processing/clc5_class3_class4_3035_DE_5m_inverse_warp_exts.tif\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: CLIP TO CORINE FOOTPRINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: SUBTRACT INVERSE RASTER\n",
    "\n",
    "# Store paths to the two input maps\n",
    "jaxa_FNF = \"./outputs/jaxa_FNF_3035_DE_5m_FNF.tif\"\n",
    "ger_lulc_inverse = \"\"\n",
    "\n",
    "# Runs gdal_calc.py to subtract the input rasters  \n",
    "adjusted_jaxa = subprocess.run(['python', \n",
    "                                gdal_calc, \n",
    "                                '-A', jaxa_FNF, \n",
    "                                '-B', ger_lulc_inverse, \n",
    "                                '--outfile=./processing/jaxa_3035_DE_5m_adjusted.tif', \n",
    "                                '--calc=A-B', \n",
    "                                '--co=COMPRESS=LZW', \n",
    "                                '--co=BIGTIFF=YES', \n",
    "                                '--NoDataValue=-9999'\n",
    "                                ],\n",
    "                                capture_output=True, \n",
    "                                text=True)\n",
    "\n",
    "print(adjusted_jaxa.stdout)\n",
    "print(adjusted_jaxa.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Combine adjusted JAXA FNF with GER LULC FNF\n",
    "\n",
    "The JAXA map now meets the FAO requirements so it can be added together with the GER LULC FNF map (which also is within the FAO definition thresholds).\n",
    "\n",
    "The output from adding the two maps together will include values 0 to 2, so the final step is to convert the map back into a FNF output (with only values of 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: COMBINE ADJUSTED JAXA & GER LULC\n",
    "\n",
    "# Store paths to the two input maps\n",
    "adjusted_jaxa_FNF = \"./processing/jaxa_3035_DE_5m_adjusted.tif\"\n",
    "ger_lulc_FNF = \"./outputs/clc5_class3xx_3035_DE_5m_FNF.tif\"\n",
    "\n",
    "# Runs gdal_calc.py to add the input rasters together \n",
    "initial_fao = subprocess.run(['python', \n",
    "                              gdal_calc, \n",
    "                              '-A', adjusted_jaxa_FNF, \n",
    "                              '-B', ger_lulc_FNF, \n",
    "                              '--outfile=./processing/fao_3035_DE_5m_calc.tif', \n",
    "                              '--calc=A+B', \n",
    "                              '--co=COMPRESS=LZW', \n",
    "                              '--co=BIGTIFF=YES', \n",
    "                              '--NoDataValue=-9999'\n",
    "                              ],\n",
    "                              capture_output=True, \n",
    "                              text=True)\n",
    "\n",
    "print(initial_fao.stdout)\n",
    "print(initial_fao.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: RECLASSIFY TO FNF\n",
    "\n",
    "# Store path to initial FAO map\n",
    "initial_fao = \"./processing/fao_3035_DE_5m_calc.tif\"\n",
    "\n",
    "# Runs gdal_calc.py in order to reclassify to FNF\n",
    "reclass_fao = subprocess.run(['python', \n",
    "                              gdal_calc, \n",
    "                              '-A', initial_fao, \n",
    "                              '--outfile=./processing/fao_3035_DE_5m_calc_reclass.tif', \n",
    "                              '--calc=-9999*(A==-9999)+0*(A==0)+1*(A==1)+1*(A==2)', \n",
    "                              '--co=COMPRESS=LZW', \n",
    "                              '--co=BIGTIFF=YES', \n",
    "                              '--NoDataValue=-9999'\n",
    "                              ],\n",
    "                              capture_output=True, \n",
    "                              text=True)\n",
    "\n",
    "print(reclass_fao.stdout)\n",
    "print(reclass_fao.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Copy & Rename\n",
    "\n",
    "After visually checking the rasters in QGIS, the outputs from the last step seem to meet all the requirments! I now copy over the raster to the \"outputs\" folder and rename it to indicate it is the FNF output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: COPY & RENAME\n",
    "\n",
    "# Store the path to the old version (to be copied & renamed)\n",
    "fao_old = \"./processing/fao_3035_DE_5m_calc_reclass.tif\"\n",
    "\n",
    "# Copy & rename the raster\n",
    "shutil.copy(fao_old, \"./outputs/\" + os.path.split(fao_old)[1][:-16] + \"FNF.tif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
