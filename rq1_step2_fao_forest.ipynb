{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1 Creating FAO forest map\n",
    "\n",
    "This script is focused on creating one of the forest products (the FAO-aligned definition) for comparison with the other forest products as part of **RQ1: What is considered to be forest?** The steps generally follow the approach taken in Johnson et al (2023).\n",
    "\n",
    "As a bit of background for the GER LULC class numbers:\n",
    "- Class 3 corresponds to mainly in-land natural land covers: forest, grasslands, moors/heathland, transitional woodland/shrub, beaches/dunes, bare rock, sparsely vegetated areas, burnt areas and glaciers or perpetual snow\n",
    "- Class 4 corresponds to coastal natural land covers: inland marshes, peatbogs, coastal salt marshes and intertidal flats\n",
    "- the remaining classes correspond to urban areas (Class 1), agricultural areas (Class 2) and water bodies (Class 5)\n",
    "\n",
    "Steps:\n",
    "1. Rasterise GER LULC Class 3 & 4\n",
    "2. Mask JAXA FNF with GER LULC Class 3 & 4\n",
    "3. Combine adjusted JAXA FNF with GER LULC FNF\n",
    "4. Copy & rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "\n",
    "# Note: this .ipynb file depends on files & folder structures created in rq1_step1_data_prep.ipynb\n",
    "\n",
    "# Import packages\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "# Store gdal.exe paths\n",
    "gdal_rasterize = \"./thesis_env_conda/Library/bin/gdal_rasterize.exe\"\n",
    "gdalwarp = \"./thesis_env_conda/Library/bin/gdalwarp.exe\"\n",
    "\n",
    "# Store gdal.py paths\n",
    "gdal_calc = \"./thesis_env_conda/Lib/site-packages/GDAL-3.10.1-py3.12-win-amd64.egg-info/scripts/gdal_calc.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Rasterise GER LULC Class 3 & 4\n",
    "\n",
    "Originally I planned to use a vector of the GER LULC Class 3 and 4 as a clipper to extract only those areas from the JAXA FNF raster. However, this resulted in a very complex vector and the clipping process was prohibitively slow. \n",
    "\n",
    "Instead I decided to rasterise the GER LULC 3 and 4 Classes which correspond to natural areas (value of 1 for these classes and 0 everywhere else). I can then use this raster to remove the non-class-3 and non-class-4 (urban and agricultural areas plus water bodies) areas from the JAXA FNF map by multiplying the two together. \n",
    "\n",
    "Note the dissolve and explode steps are not totally needed (previously they were required for creating a clipper shp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: COMBINE GER LULC SHPS\n",
    "# TAKES ABOUT 15 MIN\n",
    "\n",
    "# Load all the GER LULC SHPs (no data from the attribute table is needed)\n",
    "ger_lulc_class3_shp = gpd.read_file(\"./processing/clc5_class3xx_3035_DE.shp\", columns = [\"\"])\n",
    "ger_lulc_class4_shp = gpd.read_file(\"./processing/clc5_class4xx_3035_DE.shp\", columns = [\"\"])\n",
    "\n",
    "# Append the shapefiles together\n",
    "merged_ger_lulc_shp = pd.concat([ger_lulc_class3_shp,\n",
    "                                 ger_lulc_class4_shp,\n",
    "                                 ])\n",
    "\n",
    "# Dissolve the geometries (this creates one multi-part geometry)\n",
    "dissolved_ger_lulc_shp = merged_ger_lulc_shp.dissolve()\n",
    "\n",
    "# Explode the multi-part geometry into multiple single geometries\n",
    "exploded_ger_lulc_shp = dissolved_ger_lulc_shp.explode()\n",
    "\n",
    "# Write the merged, dissolved & exploded output to file\n",
    "exploded_ger_lulc_shp.to_file('./processing/clc5_class3_class4_3035_DE.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1: RASTERISATION\n",
    "# ABOUT 25 MIN\n",
    "\n",
    "# Store path to shp for rasterising\n",
    "gerlulc_3_4_shp = \"./processing/clc5_class3_class4_3035_DE.shp\"\n",
    "\n",
    "# Store path/filename for rasterised output\n",
    "gerlulc_3_4_tif = \"./processing/clc5_class3_class4_3035_DE_5m.tif\"\n",
    "\n",
    "# Run gdal_rasterize to create GER LULC Class 3 & 4 raster\n",
    "# I removed the inversion as this caused it to run for hours without producing data (1 KB file only)\n",
    "# '-i' flag: invert rasterisation (burn value is burned into all parts NOT inside the polygons)\n",
    "gerlulc_rasterise = subprocess.run([gdal_rasterize, \n",
    "                                    '-l', 'clc5_class3_class4_3035_DE',\n",
    "                                    '-burn', '1',\n",
    "                                    #'-i',    \n",
    "                                    '-tr', '5', '5',\n",
    "                                    '-a_nodata', '-9999', \n",
    "                                    '-ot', 'Int16', \n",
    "                                    '-of', 'GTiff',\n",
    "                                    '-co', 'COMPRESS=LZW', \n",
    "                                    '-co', 'BIGTIFF=YES', \n",
    "                                    gerlulc_3_4_shp,\n",
    "                                    gerlulc_3_4_tif\n",
    "                                    ],\n",
    "                                    capture_output=True, \n",
    "                                    text=True)\n",
    "\n",
    "print(gerlulc_rasterise.stdout)\n",
    "print(gerlulc_rasterise.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: CONVERT NODATA TO VALID VALUE \n",
    "# Block/window processing is needed to work with the data in chunks, otherwise I hit memory problems!\n",
    "\n",
    "# Input file\n",
    "gerlulc_3_4_tif = \"./processing/clc5_class3_class4_3035_DE_5m.tif\"\n",
    "\n",
    "# Output file\n",
    "gerlulc_3_4_fix = \"./processing/clc5_class3_class4_3035_DE_5m_reclass.tif\"\n",
    "\n",
    "# Open input raster\n",
    "with rasterio.open(gerlulc_3_4_tif) as input:\n",
    "    # Copy profile (metadata) from input\n",
    "    profile = input.profile.copy()  \n",
    "    # Update profile (metdata) for output\n",
    "    profile.update(dtype=rasterio.int16, nodata=-9999, compress=\"LZW\")  \n",
    "\n",
    "    # Create the output using the updated profile (metadata)\n",
    "    with rasterio.open(gerlulc_3_4_fix, 'w', **profile) as output:\n",
    "        # Process each block one at a time \n",
    "        for ji, window in input.block_windows(1):     # the 1 here indicates band 1\n",
    "            # Store the data for a block\n",
    "            data = input.read(1, window=window)       # the 1 here indicates band 1 \n",
    "            # Replace NoData values (-9999) with 0 for a block\n",
    "            data[data == -9999] = 0\n",
    "            # Write the adjusted data for a block to the output raster\n",
    "            output.write(data, 1, window=window) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Mask JAXA FNF with GER LULC Class 3 & 4\n",
    "\n",
    "Using the raster from step 1, the next step is to adjust the JAXA FNF map so that all non-class-3 and non-class-4 forests are removed. This can be achieved by multiplying the rasters, so that non-class-3 and non-class-4 areas are converted to 0. This removes any areas of forest in the JAXA map which are in predominantly agricultural or urban areas.\n",
    "\n",
    "Before I multiply the two layers, the extents will need to match - so here I follow a similar process as in \"rq1_step1_data_prep.ipynb\" to clip and adjust the extents of the GER LULC Class 3 & 4 raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating output file that is 128214P x 173470L.\n",
      "Using internal nodata values (e.g. -9999) for image ./processing/clc5_class3_class4_3035_DE_5m_reclass.tif.\n",
      "Processing ./processing/clc5_class3_class4_3035_DE_5m_reclass.tif [1/1] : 0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2: CLIP TO CORINE BBOX\n",
    "# TAKES ABOUT 33 MIN\n",
    "\n",
    "# Store path to CORINE bbox shp (created in \"rq1_step1_data_prep.ipynb\")\n",
    "corine_bbox_shp = \"./processing/corine_reclass_bbox.shp\"\n",
    "\n",
    "# Define function that clips tifs to the CORINE bbox (copy from \"rq1_step1_data_prep.ipynb\")\n",
    "def bbox_clip(input_paths):\n",
    "    # Iterate through the paths \n",
    "    for path in input_paths:\n",
    "        # For output file naming: extract the input file name (with extension)\n",
    "        name_w_ext = os.path.split(path)[1] \n",
    "        # For output file naming: remove extension\n",
    "        root_name = name_w_ext[:-4]\n",
    "        # For output file naming: assemble the new file path for the output\n",
    "        output_path = \"./processing/\" + root_name + \"_bboxclip.tif\"\n",
    "\n",
    "        # Run warp to crop to the CORINE bbox\n",
    "        clip_to_bbox = subprocess.run([gdalwarp, \n",
    "                                       '-crop_to_cutline', \n",
    "                                       '-cutline', corine_bbox_shp, \n",
    "                                       '-tr', '5', '5',\n",
    "                                       '-dstnodata', '-9999', \n",
    "                                       '-ot', 'Int16', \n",
    "                                       '-co', 'COMPRESS=LZW', \n",
    "                                       '-co', 'BIGTIFF=YES', \n",
    "                                       path, \n",
    "                                       output_path\n",
    "                                       ],\n",
    "                                       capture_output=True, \n",
    "                                       text=True)\n",
    "        print(clip_to_bbox.stdout)\n",
    "        print(clip_to_bbox.stderr)\n",
    "\n",
    "# Run just for the single raster\n",
    "bbox_clip([\"./processing/clc5_class3_class4_3035_DE_5m_reclass.tif\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating output file that is 128214P x 173470L.\n",
      "Using internal nodata values (e.g. -9999) for image ./processing/clc5_class3_class4_3035_DE_5m_reclass_bboxclip.tif.\n",
      "Copying nodata values from source ./processing/clc5_class3_class4_3035_DE_5m_reclass_bboxclip.tif to destination ./processing/clc5_class3_class4_3035_DE_5m_reclass_bboxclip_warp_exts.tif.\n",
      "Processing ./processing/clc5_class3_class4_3035_DE_5m_reclass_bboxclip.tif [1/1] : 0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2: WARP EXTENTS\n",
    "# TAKE ABOUT 17 MIN\n",
    "\n",
    "# First, extract the extents from the CORINE data (created in \"rq1_step1_data_prep.ipynb\")\n",
    "corine_ref = rasterio.open(\"./processing/U2018_CLC2018_V2020_3035_DE_5m_bboxclip.tif\")\n",
    "corine_bounds  = corine_ref.bounds\n",
    "\n",
    "# Store the bounds in the format required for gdalwarp\n",
    "corine_xmin = str(corine_bounds[0])       # xmin = left\n",
    "corine_ymin = str(corine_bounds[1])       # ymin = bottom\n",
    "corine_xmax = str(corine_bounds[2])       # xmax = right\n",
    "corine_ymax = str(corine_bounds[3])       # ymax = top\n",
    "\n",
    "# Define function that warps rasters to the CORINE extents (copy from \"rq1_step1_data_prep.ipynb\")\n",
    "def corine_warp(input_paths):\n",
    "    # Iterate through the paths \n",
    "    for path in input_paths:\n",
    "        # For output file naming: extract the input file name (with extension)\n",
    "        name_w_ext = os.path.split(path)[1] \n",
    "        # For output file naming: remove extension from input file name\n",
    "        name_wo_ext = os.path.splitext(name_w_ext)[0]\n",
    "        # For output file naming: assemble the new file path for the output\n",
    "        output_path = \"./processing/\" + name_wo_ext + \"_warp_exts.tif\"\n",
    "        \n",
    "        # Run warp to match all rasters to CORINE extents\n",
    "        warp_extents = subprocess.run([gdalwarp, \n",
    "                                      '-t_srs', 'EPSG:3035', \n",
    "                                      #'-tr', '5', '5',\n",
    "                                      '-te', corine_xmin, corine_ymin, corine_xmax, corine_ymax,\n",
    "                                      #'-tap',\n",
    "                                      '-ot', 'Int16', \n",
    "                                      '-co', 'COMPRESS=LZW', \n",
    "                                      '-co', 'BIGTIFF=YES', \n",
    "                                      path, \n",
    "                                      output_path\n",
    "                                      ],\n",
    "                                      capture_output=True, \n",
    "                                      text=True)\n",
    "        print(warp_extents.stdout)\n",
    "        print(warp_extents.stderr)\n",
    "\n",
    "\n",
    "# Separate Hansen processing\n",
    "corine_warp([\"./processing/clc5_class3_class4_3035_DE_5m_reclass_bboxclip.tif\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2: MULTIPLY RASTERS\n",
    "# TAKES ABOUT 8 MIN\n",
    "\n",
    "# Store paths to the two input maps\n",
    "jaxa_FNF = \"./processing/jaxa_FNF_3035_DE_5m_bboxclip_warp_exts.tif\" # matches extents of adjuster!\n",
    "ger_lulc_adjuster = \"./processing/clc5_class3_class4_3035_DE_5m_reclass_bboxclip_warp_exts.tif\"\n",
    "\n",
    "# Runs gdal_calc.py to subtract the input rasters  \n",
    "adjusted_jaxa = subprocess.run(['python', \n",
    "                                gdal_calc, \n",
    "                                '-A', jaxa_FNF, \n",
    "                                '-B', ger_lulc_adjuster, \n",
    "                                '--outfile=./processing/jaxa_3035_DE_5m_adjusted.tif', \n",
    "                                '--calc=A*B', \n",
    "                                '--co=COMPRESS=LZW', \n",
    "                                '--co=BIGTIFF=YES', \n",
    "                                '--NoDataValue=-9999'\n",
    "                                ],\n",
    "                                capture_output=True, \n",
    "                                text=True)\n",
    "\n",
    "print(adjusted_jaxa.stdout)\n",
    "print(adjusted_jaxa.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Combine adjusted JAXA FNF with GER LULC FNF\n",
    "\n",
    "The JAXA map now meets the FAO requirements so it can be added together with the GER LULC FNF map (which also is within the FAO definition thresholds).\n",
    "\n",
    "The output from adding the two maps together will include values 0 to 2, so the final step is to convert the map back into a FNF output (with only values of 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3: COMBINE ADJUSTED JAXA & GER LULC\n",
    "# TAKES ABOUT 10 MIN\n",
    "\n",
    "# Store paths to the two input maps\n",
    "adjusted_jaxa_FNF = \"./processing/jaxa_3035_DE_5m_adjusted.tif\"\n",
    "ger_lulc_FNF = \"./processing/clc5_class3xx_3035_DE_5m_bboxclip_warp_exts.tif\" # matches extents!\n",
    "\n",
    "# Runs gdal_calc.py to add the input rasters together \n",
    "initial_fao = subprocess.run(['python', \n",
    "                              gdal_calc, \n",
    "                              '-A', adjusted_jaxa_FNF, \n",
    "                              '-B', ger_lulc_FNF, \n",
    "                              '--outfile=./processing/fao_approx_3035_DE_5m_calc.tif', \n",
    "                              '--calc=A+B', \n",
    "                              '--co=COMPRESS=LZW', \n",
    "                              '--co=BIGTIFF=YES', \n",
    "                              '--NoDataValue=-9999'\n",
    "                              ],\n",
    "                              capture_output=True, \n",
    "                              text=True)\n",
    "\n",
    "print(initial_fao.stdout)\n",
    "print(initial_fao.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3: RECLASSIFY TO FNF\n",
    "# TAKES ABOUT 10 MIN\n",
    "\n",
    "# Store path to initial FAO map\n",
    "initial_fao = \"./processing/fao_approx_3035_DE_5m_calc.tif\"\n",
    "\n",
    "# Runs gdal_calc.py in order to reclassify to FNF\n",
    "reclass_fao = subprocess.run(['python', \n",
    "                              gdal_calc, \n",
    "                              '-A', initial_fao, \n",
    "                              '--outfile=./processing/fao_approx_3035_DE_5m_calc_reclass.tif', \n",
    "                              '--calc=-9999*(A==-9999)+0*(A==0)+1*(A==1)+1*(A==2)', \n",
    "                              '--co=COMPRESS=LZW', \n",
    "                              '--co=BIGTIFF=YES', \n",
    "                              '--NoDataValue=-9999'\n",
    "                              ],\n",
    "                              capture_output=True, \n",
    "                              text=True)\n",
    "\n",
    "print(reclass_fao.stdout)\n",
    "print(reclass_fao.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating output file that is 128212P x 173469L.\n",
      "Using internal nodata values (e.g. -9999) for image ./processing/fao_approx_3035_DE_5m_calc_reclass.tif.\n",
      "Processing ./processing/fao_approx_3035_DE_5m_calc_reclass.tif [1/1] : 0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3: CLIP TO CORINE FOOTPRINT\n",
    "# TAKES ABOUT 170 MIN\n",
    "\n",
    "# Store path to the input map \n",
    "reclass_fao = \"./processing/fao_approx_3035_DE_5m_calc_reclass.tif\"\n",
    "\n",
    "# Store path to CORINE footprint (created in \"rq1_step1_data_prep.ipynb\")\n",
    "corine_clipper = \"./processing/clipper.shp\"\n",
    "\n",
    "# Store path to output\n",
    "clipped_fao = \"./processing/fao_approx_3035_DE_5m_calc_reclass_clipped.tif\"\n",
    "\n",
    "# Use gdalwarp to clip tif to the CORINE footprint\n",
    "clip_to_DE = subprocess.run([gdalwarp, \n",
    "                             '-crop_to_cutline', \n",
    "                             '-cutline', corine_clipper, \n",
    "                             '-tr', '5', '5',\n",
    "                             '-dstnodata', '-9999', \n",
    "                             '-ot', 'Int16', \n",
    "                             '-co', 'COMPRESS=LZW', \n",
    "                             '-co', 'BIGTIFF=YES', \n",
    "                             reclass_fao, \n",
    "                             clipped_fao                    \n",
    "                             ],\n",
    "                             capture_output=True,           \n",
    "                             text=True)\n",
    "         \n",
    "print(clip_to_DE.stdout)\n",
    "print(clip_to_DE.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Copy & Rename\n",
    "\n",
    "After visually checking the raster in QGIS, the output from the last step seems to meet all the requirments! I now copy over the raster to the \"outputs\" folder and rename it to indicate it is the final FNF output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./outputs/fao_approx_3035_DE_5m_2018_FNF.tif'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4: COPY & RENAME\n",
    "\n",
    "# Store the path to the old version (to be copied & renamed)\n",
    "fao_old = \"./processing/fao_approx_3035_DE_5m_calc_reclass_clipped.tif\"\n",
    "\n",
    "# Copy & rename the raster\n",
    "shutil.copy(fao_old, \"./outputs/\" + os.path.split(fao_old)[1][:-24] + \"2018_FNF.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Citations:**\n",
    "\n",
    "Johnson, B. A., Umemiya, C., Magcale-Macandog, D. B., Estoque, R. C., Hayashi, M., & Tadono, T. (2023). Better monitoring of forests according to FAOâ€™s definitions through map integration: Significance and limitations in the context of global environmental goals. *International Journal of Applied Earth Observation and Geoinformation, 122,* 103452. https://doi.org/10.1016/j.jag.2023.103452"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
