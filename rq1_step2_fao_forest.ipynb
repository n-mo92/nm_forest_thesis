{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1 Creating FAO forest map\n",
    "\n",
    "[Add Description]\n",
    "\n",
    "Need to create a FAO Definition Approximation following the steps from Johnson et al (2023)\n",
    "\n",
    "Steps:\n",
    "1. Data Preparation\n",
    "    1. Clip the 5 GER LULC shapefiles to the Natura 2000 areas\n",
    "    2. Merge the clipped 5 GER LULC shapefiles into 1 shapefile\n",
    "    3. Vectorise the clipped 5m JAXA raster\n",
    "2. Intersect JAXA and GER LULC shapefiles\n",
    "3. Conditional Reclassing\n",
    "4. Convert to 5m raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "\n",
    "# Note: this .ipynb file depends on files & folder structures created in rq1_step1_data_prep.ipynb\n",
    "\n",
    "# Import packages\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Preparation\n",
    "\n",
    "#### Step 1.1: Clip GER LULC SHPs\n",
    "\n",
    "In the rq1_step1_data_prep.ipynb file, I clipped all the output **rasters** to the Germany Natura 2000 areas - in this first data prep step, I do the same for the GER LULC shapefiles, as I will be working with vector data for creating the FAO-aligned forest map. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIP GER LULC SHPS\n",
    "\n",
    "# Store paths to reprojected GER LULC SHPs in a list\n",
    "ger_lulc_paths = glob.glob('./processing/clc5_class*xx_3035_DE.shp')\n",
    "\n",
    "# Create a function which which clips the shp to the Germany Natura areas (& saves to processing folder)\n",
    "def clip_shp_to_natura(input_paths):\n",
    "    # Load Germany Natura 2000 areas\n",
    "    natura_de_gdf = gpd.read_file(\"./outputs/natura2000_3035_DE.shp\")\n",
    "    # Iterate through the GER LULC shp paths \n",
    "    for path in input_paths:\n",
    "        # Open the shp for each path \n",
    "        ger_lulc_shp = gpd.read_file(path)\n",
    "        \n",
    "        # Clip input GER LULC shp to Natura shp\n",
    "        shp_clip  = gpd.clip(ger_lulc_shp, natura_de_gdf)\n",
    "\n",
    "        # For output file naming: extract the input file name (with extension)\n",
    "        name_w_ext = os.path.split(path)[1] \n",
    "        # For output file naming: remove extension from input file name \n",
    "        name_wo_ext = os.path.splitext(name_w_ext)[0]\n",
    "        # For output file naming: create the new name for clipped shp\n",
    "        new_name = name_wo_ext + \"_clipped.shp\"\n",
    "\n",
    "        # Write the reprojected shp to the processing folder\n",
    "        shp_clip.to_file('./processing/' + new_name)\n",
    "\n",
    "# Run the function for the German LULC zipped shps\n",
    "clip_shp_to_natura(ger_lulc_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.2: Merge clipped GER LULC to 1 shp \n",
    "\n",
    "In order to make the next steps easier, all the clipped GER LULC shps can be merged into 1 master shp. \n",
    "\n",
    "Help for merging/appending shps: https://geopandas.org/en/stable/docs/user_guide/mergingdata.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE GER LULC SHPS\n",
    "\n",
    "# Load all the GER LULC SHPs\n",
    "ger_lulc_class1_shp = gpd.read_file(\"./outputs/clc5_class1xx_3035_DE_clipped.shp\")\n",
    "ger_lulc_class2_shp = gpd.read_file(\"./outputs/clc5_class2xx_3035_DE_clipped.shp\")\n",
    "ger_lulc_class3_shp = gpd.read_file(\"./outputs/clc5_class3xx_3035_DE_clipped.shp\")\n",
    "ger_lulc_class4_shp = gpd.read_file(\"./outputs/clc5_class4xx_3035_DE_clipped.shp\")\n",
    "ger_lulc_class5_shp = gpd.read_file(\"./outputs/clc5_class5xx_3035_DE_clipped.shp\")\n",
    "\n",
    "# Append the shapefiles together\n",
    "merged_ger_lulc_shp = pd.concat([ger_lulc_class1_shp,\n",
    "                                 ger_lulc_class2_shp,\n",
    "                                 ger_lulc_class3_shp,\n",
    "                                 ger_lulc_class4_shp,\n",
    "                                 ger_lulc_class5_shp\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.3: Reclassify & vectorise clipped Jaxa\n",
    "\n",
    "In order to implement the workflow for creating the FAO-aligned forest map, all input data must be vectors. In this step I vectorise the clipped JAXA 5m raster - but first I reclassify the raster to get rid of unneeded information.\n",
    "\n",
    "Help with reclassifying (use gdal_calc): https://gis.stackexchange.com/questions/245170/reclassifying-raster-using-gdal \n",
    "\n",
    "Help with raster to vector: https://py.geocompx.org/05-raster-vector\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
