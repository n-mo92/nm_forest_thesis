{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ2 Data Collection\n",
    "\n",
    "Wikiloc data extraction for Germany. **See scrapy_setup_info.md for setting up scrapy, including edits I made to the settings to fix 403 error messages and make the scraping more polite.**\n",
    "\n",
    "scrapy spiders are provided by Chai-Allah et al, 2023 through their GitHub repo: [Wiki4CES](https://github.com/achaiallah-hub/Wiki4CES)\n",
    "\n",
    "From what I understand, the spiders provided in the Wiki4CES repo do the following:\n",
    "1. **extract_link.py** Extracts the URLS for all the trails. You give it a starting region (an intital URL) and it goes through each city/town in that region and extracts all the trail links (URLS) in the cities listing. This spider neeeds to be run first to get the URLS for steps 2 and 3. \n",
    "2. **wikiloc_track.py** Scrapes the trail details like track name, difficulty, distance, author, views and description. It loads the trail URLs from a file called link.csv (presumably created in step 1)\n",
    "3. **wikiloc_image.py** Scrapes image data from the trail pages, including URL, track name, user name, date, and location (latitude & longitude). It reads the trail pages from a file called link.csv (presumably created in step 1)\n",
    "4. **download_image.py** Downloads images from the URLS in a csv file called wikiloc_image.csv (presumably this would be created from step 3). Not needed for my work, so I have removed this file\n",
    "\n",
    "**NOTE:** For some reason, running one spider seems to try to run all the spiders at once, and you end up getting error messages saying certain files don't exist (which makes sense as these files need to be created by certain spiders first). I tried looking for the solution for this, but for now I've just commented out the code within the other spiders. UPDATE: It seems to be okay once the errors have been resolved (it doesn't actually run the other spiders but seem to check for the correct files and the code being valid?), so I'm leaving finished scripts uncommented as I correct them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ./wikiloc_scrapy/wikiloc_scrapy/spiders/crawling_outputs already exists\n"
     ]
    }
   ],
   "source": [
    "# SETUP\n",
    "\n",
    "# Import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from shapely.geometry import box\n",
    "import geopandas as gpd\n",
    "\n",
    "# Create folders for storing scrapy outputs\n",
    "path_list = [\"./wikiloc_scrapy/wikiloc_scrapy/spiders/crawling_outputs\"]\n",
    "\n",
    "for path in path_list:\n",
    "  if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "    print(\"Folder %s created!\" % path)\n",
    "  else:\n",
    "    print(\"Folder %s already exists\" % path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Updating extract_link.py\n",
    "\n",
    "**Step 1a: Update starting_urls (including Germany region info)** \n",
    "Edit the extract_link.py to replace the staring_urls. Originally this contained https://www.wikiloc.com/trails/france/auvergne-rhone-alpes - this URL doesn't seem to exist anymore as it just redirects to https://www.wikiloc.com/trails/outdoor. \n",
    "\n",
    "The URL format now needs to be https://www.wikiloc.com/trails/outdoor/ + *country_name* + *region_name* so for Germany I will try https://www.wikiloc.com/trails/outdoor/germany and then each of the regions within.\n",
    "\n",
    "For Germany, Wikiloc has trails for the following regions:\n",
    "\n",
    "| Count | Region                 | URL ending              |\n",
    "| ----- | ---------------------- | ----------------------- | \n",
    "| 1     | Baden-Wurttemberg      | /baden-wurttemberg      | \n",
    "| 2     | Bavaria                | /bavaria                |\n",
    "| 3     | Berlin                 | /berlin                 |\n",
    "| 4     | Brandenburg            | /brandenburg            |\n",
    "| 5     | Bremen                 | /bremen                 |\n",
    "| -     | DE.16,11               | (don't use)             |\n",
    "| 6     | Hamburg                | /hamburg                |\n",
    "| 7     | Hessen                 | /hessen                 |\n",
    "| 8     | Mecklenburg-Vorpommern | /mecklenburg-vorpommern |\n",
    "| 9     | Niedersachsen          | /niedersachsen          |\n",
    "| 10    | Nordrhein-Westfalen    | /nordrhein-westfalen    |\n",
    "| 11    | Rheinland-Pfalz        | /rheinland-pfalz        |\n",
    "| 12    | Saarland               | /saarland               |\n",
    "| 13    | Sachsen                | /sachsen                |\n",
    "| 14    | Saxony-Anhalt          | /saxony-anhalt          |\n",
    "| 15    | Schleswig-Holstein     | /schleswig-holstein     |\n",
    "| 16    | Thüringen              | /thuringen              |\n",
    "\n",
    "*NOTE* The number of trails being added seem to be increasing steadily (for example, within a one week period, the total count for Germany went up by ~1000). I'll need to keep track of the number of expected trails on the day of download. Also check to make sure no new regions are added!\n",
    "\n",
    "DE.16,11 appears to be a few trails in Berlin - I don't think I need to bother with this as there is so few and in an urban area (and all the routes don't really look like anything to do with forests)\n",
    "\n",
    "**Step 1b: Update xpath expressions & other edits**\n",
    "After overcoming initial 403 error messages (see scrapy_setup_info.md), the spider seemed to correctly generate the urls for all the cities within the region, but still didn't return the trail URLs. I started looking into the xpath expressions in the extract_link.py as I wondered if the path structure has changed a bit over time (like the URLs).\n",
    "\n",
    "I found this video useful for understanding xpath https://www.youtube.com/watch?v=4EvxqTSzUkI \n",
    "I then went to https://www.wikiloc.com/trails/outdoor/germany/bremen and did rick click > Inspect to see the html (I selected Bremen as the testing region as it has the fewest trails). After a search for the components on the main Bremen page and then for one city (for example: https://www.wikiloc.com/trails/outdoor/germany/bremen/alte-neustadt) I made a couple changed to the xpaths in extract_link.py (see comments in script). I also made some changes to the pagination handling (see comments in script). ALSO, since the URLs saved initially were just the back half of the URL, without the beginning (eg. /cycling-trails/bremen-achim-18077390) I adjusted the code to add the beginning part as well. This ended up being required for the other spiders to work properly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Complete workflow for running extract_link.py\n",
    "\n",
    "*For now, this is just for the Bremen region.*\n",
    "\n",
    "**Step 2a**\n",
    "In extract_link.py:\n",
    "1. Update start_urls: 'https://www.wikiloc.com/trails/outdoor/germany/bremen' and save.\n",
    "\n",
    "**Step 2b**\n",
    "In Anaconda Prompt:\n",
    "1. conda activate C:\\Users\\ninam\\Documents\\UZH\\04_Thesis\\code\\nm_forest_thesis\\thesis_env_conda\n",
    "2. cd C:\\Users\\ninam\\Documents\\UZH\\04_Thesis\\code\\nm_forest_thesis\\wikiloc_scrapy\\wikiloc_scrapy\\spiders\n",
    "3. scrapy crawl wiki -o crawling_outputs\\link-bremen.csv\n",
    "\n",
    "**Step 2c**\n",
    "Remove duplicates: I am not sure why duplicates are occuring, but the code below simply removes any duplicates.\n",
    "\n",
    "*NOTE:* For Bremen at the time of scraping (31 MARCH 2025), the website shows 1460 trails, however I get 1532 trails (after the duplicates are removed) - this means there are an extra 72 trails. I'm not sure why this is but I wonder if it has something to do with trails which cross borders (and therefore are in more than 1 region of Germany). It could be that these trails can be searched for in both regions but are only included in the count of 1 to avoid double-counting? **I should check for duplicates across regions to make sure all trails are unique.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.wikiloc.com/hiking-trails/rundwand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.wikiloc.com/offroading-trails/30-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.wikiloc.com/hiking-trails/rund-alt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.wikiloc.com/hiking-trails/alt-burl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.wikiloc.com/running-trails/alt-wol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30387</th>\n",
       "      <td>https://www.wikiloc.com/hiking-trails/altenau-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30388</th>\n",
       "      <td>https://www.wikiloc.com/hiking-trails/altenau-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30389</th>\n",
       "      <td>https://www.wikiloc.com/running-trails/altenau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30390</th>\n",
       "      <td>https://www.wikiloc.com/hiking-trails/oderteic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30391</th>\n",
       "      <td>https://www.wikiloc.com/hiking-trails/altenau-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30392 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Link\n",
       "0      https://www.wikiloc.com/hiking-trails/rundwand...\n",
       "1      https://www.wikiloc.com/offroading-trails/30-m...\n",
       "2      https://www.wikiloc.com/hiking-trails/rund-alt...\n",
       "3      https://www.wikiloc.com/hiking-trails/alt-burl...\n",
       "4      https://www.wikiloc.com/running-trails/alt-wol...\n",
       "...                                                  ...\n",
       "30387  https://www.wikiloc.com/hiking-trails/altenau-...\n",
       "30388  https://www.wikiloc.com/hiking-trails/altenau-...\n",
       "30389  https://www.wikiloc.com/running-trails/altenau...\n",
       "30390  https://www.wikiloc.com/hiking-trails/oderteic...\n",
       "30391  https://www.wikiloc.com/hiking-trails/altenau-...\n",
       "\n",
       "[30392 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 2C: Remove CSV duplicates \n",
    "\n",
    "# Store scrapy spider path (where outputs are stored)\n",
    "scrapy_output = \"./wikiloc_scrapy/wikiloc_scrapy/spiders/crawling_outputs/\"\n",
    "\n",
    "# Create a list of the link CSVs\n",
    "link_csv_list = [\"link-bremen.csv\", \"link-niedersachsen.csv\"]\n",
    "\n",
    "# Load csvs from list, remove duplicates and then write results to same file (overwrite)\n",
    "for csv in link_csv_list:\n",
    "    loaded_csv = pd.read_csv(scrapy_output + csv, sep=\"\\t\")\n",
    "    loaded_csv.drop_duplicates(inplace=True)\n",
    "    loaded_csv.to_csv(scrapy_output + csv, index=False)\n",
    "\n",
    "# Check\n",
    "#link_bremen = pd.read_csv(scrapy_output + \"link-bremen.csv\", sep=\"\\t\")\n",
    "#link_bremen\n",
    "link_nieder = pd.read_csv(scrapy_output + \"link-niedersachsen.csv\", sep=\"\\t\")\n",
    "link_nieder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: updating wikiloc_track.py\n",
    "\n",
    "I edited wikiloc_track.py to update the xpaths (as with the extract_link.py - see comments in script). I also added code so that I could also scrape additional information: \n",
    "- date recorded\n",
    "- photo/waypoint captions (title and body)\n",
    "- comments\n",
    "- **photo/waypoint latitudes and longitudes**\n",
    "- **start point latitude and longitude** (unfortunately the end point is not stored in the html)\n",
    "\n",
    "Because I handled all the coordinate extraction in this script, I did not use or update the wikiloc_image.py script (and I since deleted it from my repo). I extracted all latitude values in one column, and all longitude values in another column. I can then extract the minimum and maximum values from each column in order to create a bounding box.\n",
    "\n",
    "Additionally, I removed the author extraction completely so that no personal information is collected. \n",
    "\n",
    "Although I updated the xapths for the following features, I commented them out as I don't think I'll need them for my analysis:\n",
    "- trail difficulty\n",
    "- view counts\n",
    "- download counts\n",
    "- trail length/distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Complete workflow for running wikiloc_track.py\n",
    "\n",
    "*For now, this is just for the Bremen region.*\n",
    "\n",
    "**Step 4a**\n",
    "In wikiloc_track.py:\n",
    "1. Change CSV name in start_urls to: crawling_outputs\\link-bremen.csv\n",
    "\n",
    "**Step 4b**\n",
    "In Anaconda Prompt:\n",
    "1. conda activate C:\\Users\\ninam\\Documents\\UZH\\04_Thesis\\code\\nm_forest_thesis\\thesis_env_conda\n",
    "2. cd C:\\Users\\ninam\\Documents\\UZH\\04_Thesis\\code\\nm_forest_thesis\\wikiloc_scrapy\\wikiloc_scrapy\\spiders\n",
    "3. scrapy crawl wiki_track -o crawling_outputs\\track-bremen.json\n",
    "\n",
    "**Needs to be output as json** otherwise (as csv) the utf-8 encoding doesn't seem to work properly and the German special characters are not handled well. \n",
    "\n",
    "For Bremen (1532 trails), with download delays and autothrottle on, this stage takes about **65 minutes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Generating geometries (bbox)\n",
    "\n",
    "In step 4, I extracted all latitude values in one column, and all longitude values in another column. I can then extract the minimum and maximum values from each column in order to create a bounding box. This bounding box contains all available coordinates (without downloading the actual gpx or kml file - which is likely more invasive to scrape from the website) - this includes the trail start coordinates and any available photo/waypoint coordinates (unfortunately the trail end coordinates were not available in the htmls).\n",
    "\n",
    "The code below generates the bounding box geometries for each trail and outputs a shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ninam\\AppData\\Local\\Temp\\ipykernel_20964\\3128160881.py:30: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  bremen_gdf.to_file(\"./processing/bremen.shp\", driver='ESRI Shapefile')\n",
      "c:\\Users\\ninam\\Documents\\UZH\\04_Thesis\\code\\nm_forest_thesis\\thesis_env_conda\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'date_published' to 'date_publi'\n",
      "  ogr_write(\n",
      "c:\\Users\\ninam\\Documents\\UZH\\04_Thesis\\code\\nm_forest_thesis\\thesis_env_conda\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'description text' to 'descriptio'\n",
      "  ogr_write(\n",
      "c:\\Users\\ninam\\Documents\\UZH\\04_Thesis\\code\\nm_forest_thesis\\thesis_env_conda\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'date_recorded' to 'date_recor'\n",
      "  ogr_write(\n",
      "c:\\Users\\ninam\\Documents\\UZH\\04_Thesis\\code\\nm_forest_thesis\\thesis_env_conda\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'photo_captions' to 'photo_capt'\n",
      "  ogr_write(\n",
      "c:\\Users\\ninam\\Documents\\UZH\\04_Thesis\\code\\nm_forest_thesis\\thesis_env_conda\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Value '['Unter den Arkaden', 'Der schmale Fußgänger und Radweg', 'Der Weg + Blick Richtung Stahlwerk', 'Heute Kuchen und etwas zu trinken', 'Graffiti', 'Blumenstreifen neben dem Weg', 'Der Weg', 'Schafe und Weg unterhalb der Schifferkirche', 'Das Rad über den Deich schieben', 'Schafe Kiste', 'Hinweis auf Brückensperrung', 'Ziegenfütterung', 'Über die Hunte', 'Weser bei Elsfleth', 'Haus in Elsfleth', 'Kurze Rast', 'Sportbooschleuse Elsfleth', 'Sandstrand + Schiff', 'Käseburger Sieltief', 'Friedrichskirche Hammelwarden', 'Aussichtspunkt Harrier Kaje', 'Altes Getriebe', 'Die Gegend bei der Slipanlage Sürwüden', 'Die Deichbewohner', 'Strohauser Sieltief beim Schöpfwerk', 'Der Weg + Storch', 'KKW Unterweser', 'KKW Unterweser', 'Der Weg über den Autotunnel', 'Der Weg', 'Der Zug zurück nach Bremen']' of field photo_capt has been truncated to 254 characters.  This warning will not be emitted any more for that layer.\n",
      "  ogr_write(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>url_track</th>\n",
       "      <th>track_type</th>\n",
       "      <th>date_published</th>\n",
       "      <th>description text</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>photo_captions</th>\n",
       "      <th>comments</th>\n",
       "      <th>latitudes</th>\n",
       "      <th>longitudes</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Von Bremen nach Nordenham</td>\n",
       "      <td>https://www.wikiloc.com/bicycle-touring-trails...</td>\n",
       "      <td>Bicycle Touring</td>\n",
       "      <td>2024-05-26T17:20+0200</td>\n",
       "      <td>Das Wetter schrie heute förmlich nach einer Ra...</td>\n",
       "      <td>May 2024</td>\n",
       "      <td>[Unter den Arkaden, Der schmale Fußgänger und ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[53.071923, 53.106267, 53.11954, 53.123263, 53...</td>\n",
       "      <td>[8.806885, 8.719043, 8.68582, 8.648513, 8.6240...</td>\n",
       "      <td>8.447528</td>\n",
       "      <td>8.806885</td>\n",
       "      <td>53.071923</td>\n",
       "      <td>53.483365</td>\n",
       "      <td>POLYGON ((8.80688 53.07192, 8.80688 53.48336, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weser-Radweg Alternativroute, 7. Etappe: Von B...</td>\n",
       "      <td>https://www.wikiloc.com/hiking-trails/weser-ra...</td>\n",
       "      <td>Hiking</td>\n",
       "      <td>2019-06-07T16:36+0200</td>\n",
       "      <td>Weser-Radweg Alternativroute, 7. Etappe: Von B...</td>\n",
       "      <td>None</td>\n",
       "      <td>[Weserfähre Nordenham-Bremerhaven, Anleger Bre...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[53.536431, 53.536547, 53.167614, 53.197138, 5...</td>\n",
       "      <td>[8.580923, 8.589272, 8.619332, 8.516765, 8.500...</td>\n",
       "      <td>8.497751</td>\n",
       "      <td>8.729962</td>\n",
       "      <td>53.164652</td>\n",
       "      <td>53.536547</td>\n",
       "      <td>POLYGON ((8.72996 53.16465, 8.72996 53.53655, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indo pra praia n1</td>\n",
       "      <td>https://www.wikiloc.com/mountain-biking-trails...</td>\n",
       "      <td>Mountain Bike</td>\n",
       "      <td>2019-06-07T20:38+0200</td>\n",
       "      <td>Indo pra praia n1</td>\n",
       "      <td>June 2019</td>\n",
       "      <td>[Foto]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[53.165994, 53.162825]</td>\n",
       "      <td>[8.627444, 8.727078]</td>\n",
       "      <td>8.627444</td>\n",
       "      <td>8.727078</td>\n",
       "      <td>53.162825</td>\n",
       "      <td>53.165994</td>\n",
       "      <td>POLYGON ((8.72708 53.16282, 8.72708 53.16599, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weser-Radweg Alternativroute, 7. Etappe: Von B...</td>\n",
       "      <td>https://www.wikiloc.com/hiking-trails/weser-ra...</td>\n",
       "      <td>Hiking</td>\n",
       "      <td>2019-06-07T17:41+0200</td>\n",
       "      <td>Weser-Radweg Alternativroute, 7. Etappe: Von B...</td>\n",
       "      <td>None</td>\n",
       "      <td>[Weserfähre Nordenham-Bremerhaven, Anleger Bre...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[53.536431, 53.536547, 53.167614, 53.197138, 5...</td>\n",
       "      <td>[8.580923, 8.589272, 8.619332, 8.516765, 8.500...</td>\n",
       "      <td>8.497751</td>\n",
       "      <td>8.729962</td>\n",
       "      <td>53.164652</td>\n",
       "      <td>53.536547</td>\n",
       "      <td>POLYGON ((8.72996 53.16465, 8.72996 53.53655, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weser-Radweg Alternativroute, 7. Etappe: Von B...</td>\n",
       "      <td>https://www.wikiloc.com/hiking-trails/weser-ra...</td>\n",
       "      <td>Hiking</td>\n",
       "      <td>2019-06-07T17:34+0200</td>\n",
       "      <td>Weser-Radweg Alternativroute, 7. Etappe: Von B...</td>\n",
       "      <td>None</td>\n",
       "      <td>[Weserfähre Nordenham-Bremerhaven, Anleger Bre...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[53.536431, 53.536547, 53.167614, 53.197138, 5...</td>\n",
       "      <td>[8.580923, 8.589272, 8.619332, 8.516765, 8.500...</td>\n",
       "      <td>8.497751</td>\n",
       "      <td>8.729962</td>\n",
       "      <td>53.164652</td>\n",
       "      <td>53.536547</td>\n",
       "      <td>POLYGON ((8.72996 53.16465, 8.72996 53.53655, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>Bremen</td>\n",
       "      <td>https://www.wikiloc.com/hiking-trails/bremen-4...</td>\n",
       "      <td>Hiking</td>\n",
       "      <td>2019-12-10T16:03+0100</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>December 2019</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[53.07439]</td>\n",
       "      <td>[8.806197]</td>\n",
       "      <td>8.806197</td>\n",
       "      <td>8.806197</td>\n",
       "      <td>53.074390</td>\n",
       "      <td>53.074390</td>\n",
       "      <td>POLYGON ((8.8062 53.07439, 8.8062 53.07439, 8....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>06BremHambBikemap</td>\n",
       "      <td>https://www.wikiloc.com/outdoor-trails/06bremh...</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>2019-07-20T08:55+0200</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[53.07594]</td>\n",
       "      <td>[8.80739]</td>\n",
       "      <td>8.807390</td>\n",
       "      <td>8.807390</td>\n",
       "      <td>53.075940</td>\n",
       "      <td>53.075940</td>\n",
       "      <td>POLYGON ((8.80739 53.07594, 8.80739 53.07594, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>05LohnBrem2</td>\n",
       "      <td>https://www.wikiloc.com/outdoor-trails/05lohnb...</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>2019-07-25T08:34+0200</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[52.661410000000004]</td>\n",
       "      <td>[8.25406]</td>\n",
       "      <td>8.254060</td>\n",
       "      <td>8.254060</td>\n",
       "      <td>52.661410</td>\n",
       "      <td>52.661410</td>\n",
       "      <td>POLYGON ((8.25406 52.66141, 8.25406 52.66141, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>Kleine Nord-Tour</td>\n",
       "      <td>https://www.wikiloc.com/bicycle-touring-trails...</td>\n",
       "      <td>Bicycle Touring</td>\n",
       "      <td>2016-07-15T09:09+0200</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[51.880181]</td>\n",
       "      <td>[8.375984]</td>\n",
       "      <td>8.375984</td>\n",
       "      <td>8.375984</td>\n",
       "      <td>51.880181</td>\n",
       "      <td>51.880181</td>\n",
       "      <td>POLYGON ((8.37598 51.88018, 8.37598 51.88018, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>05DiepBremStrava</td>\n",
       "      <td>https://www.wikiloc.com/outdoor-trails/05diepb...</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>2019-07-20T08:56+0200</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[52.60442]</td>\n",
       "      <td>[8.37077]</td>\n",
       "      <td>8.370770</td>\n",
       "      <td>8.370770</td>\n",
       "      <td>52.604420</td>\n",
       "      <td>52.604420</td>\n",
       "      <td>POLYGON ((8.37077 52.60442, 8.37077 52.60442, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1532 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             track_name  \\\n",
       "0                             Von Bremen nach Nordenham   \n",
       "1     Weser-Radweg Alternativroute, 7. Etappe: Von B...   \n",
       "2                                     Indo pra praia n1   \n",
       "3     Weser-Radweg Alternativroute, 7. Etappe: Von B...   \n",
       "4     Weser-Radweg Alternativroute, 7. Etappe: Von B...   \n",
       "...                                                 ...   \n",
       "1527                                             Bremen   \n",
       "1528                                  06BremHambBikemap   \n",
       "1529                                        05LohnBrem2   \n",
       "1530                                   Kleine Nord-Tour   \n",
       "1531                                   05DiepBremStrava   \n",
       "\n",
       "                                              url_track       track_type  \\\n",
       "0     https://www.wikiloc.com/bicycle-touring-trails...  Bicycle Touring   \n",
       "1     https://www.wikiloc.com/hiking-trails/weser-ra...           Hiking   \n",
       "2     https://www.wikiloc.com/mountain-biking-trails...    Mountain Bike   \n",
       "3     https://www.wikiloc.com/hiking-trails/weser-ra...           Hiking   \n",
       "4     https://www.wikiloc.com/hiking-trails/weser-ra...           Hiking   \n",
       "...                                                 ...              ...   \n",
       "1527  https://www.wikiloc.com/hiking-trails/bremen-4...           Hiking   \n",
       "1528  https://www.wikiloc.com/outdoor-trails/06bremh...      Unspecified   \n",
       "1529  https://www.wikiloc.com/outdoor-trails/05lohnb...      Unspecified   \n",
       "1530  https://www.wikiloc.com/bicycle-touring-trails...  Bicycle Touring   \n",
       "1531  https://www.wikiloc.com/outdoor-trails/05diepb...      Unspecified   \n",
       "\n",
       "             date_published  \\\n",
       "0     2024-05-26T17:20+0200   \n",
       "1     2019-06-07T16:36+0200   \n",
       "2     2019-06-07T20:38+0200   \n",
       "3     2019-06-07T17:41+0200   \n",
       "4     2019-06-07T17:34+0200   \n",
       "...                     ...   \n",
       "1527  2019-12-10T16:03+0100   \n",
       "1528  2019-07-20T08:55+0200   \n",
       "1529  2019-07-25T08:34+0200   \n",
       "1530  2016-07-15T09:09+0200   \n",
       "1531  2019-07-20T08:56+0200   \n",
       "\n",
       "                                       description text  date_recorded  \\\n",
       "0     Das Wetter schrie heute förmlich nach einer Ra...       May 2024   \n",
       "1     Weser-Radweg Alternativroute, 7. Etappe: Von B...           None   \n",
       "2                                     Indo pra praia n1      June 2019   \n",
       "3     Weser-Radweg Alternativroute, 7. Etappe: Von B...           None   \n",
       "4     Weser-Radweg Alternativroute, 7. Etappe: Von B...           None   \n",
       "...                                                 ...            ...   \n",
       "1527                                             Bremen  December 2019   \n",
       "1528                                               None           None   \n",
       "1529                                               None           None   \n",
       "1530                                               None           None   \n",
       "1531                                               None           None   \n",
       "\n",
       "                                         photo_captions comments  \\\n",
       "0     [Unter den Arkaden, Der schmale Fußgänger und ...   [None]   \n",
       "1     [Weserfähre Nordenham-Bremerhaven, Anleger Bre...   [None]   \n",
       "2                                                [Foto]   [None]   \n",
       "3     [Weserfähre Nordenham-Bremerhaven, Anleger Bre...   [None]   \n",
       "4     [Weserfähre Nordenham-Bremerhaven, Anleger Bre...   [None]   \n",
       "...                                                 ...      ...   \n",
       "1527                                             [None]   [None]   \n",
       "1528                                             [None]   [None]   \n",
       "1529                                             [None]   [None]   \n",
       "1530                                             [None]   [None]   \n",
       "1531                                             [None]   [None]   \n",
       "\n",
       "                                              latitudes  \\\n",
       "0     [53.071923, 53.106267, 53.11954, 53.123263, 53...   \n",
       "1     [53.536431, 53.536547, 53.167614, 53.197138, 5...   \n",
       "2                                [53.165994, 53.162825]   \n",
       "3     [53.536431, 53.536547, 53.167614, 53.197138, 5...   \n",
       "4     [53.536431, 53.536547, 53.167614, 53.197138, 5...   \n",
       "...                                                 ...   \n",
       "1527                                         [53.07439]   \n",
       "1528                                         [53.07594]   \n",
       "1529                               [52.661410000000004]   \n",
       "1530                                        [51.880181]   \n",
       "1531                                         [52.60442]   \n",
       "\n",
       "                                             longitudes      xmin      xmax  \\\n",
       "0     [8.806885, 8.719043, 8.68582, 8.648513, 8.6240...  8.447528  8.806885   \n",
       "1     [8.580923, 8.589272, 8.619332, 8.516765, 8.500...  8.497751  8.729962   \n",
       "2                                  [8.627444, 8.727078]  8.627444  8.727078   \n",
       "3     [8.580923, 8.589272, 8.619332, 8.516765, 8.500...  8.497751  8.729962   \n",
       "4     [8.580923, 8.589272, 8.619332, 8.516765, 8.500...  8.497751  8.729962   \n",
       "...                                                 ...       ...       ...   \n",
       "1527                                         [8.806197]  8.806197  8.806197   \n",
       "1528                                          [8.80739]  8.807390  8.807390   \n",
       "1529                                          [8.25406]  8.254060  8.254060   \n",
       "1530                                         [8.375984]  8.375984  8.375984   \n",
       "1531                                          [8.37077]  8.370770  8.370770   \n",
       "\n",
       "           ymin       ymax                                           geometry  \n",
       "0     53.071923  53.483365  POLYGON ((8.80688 53.07192, 8.80688 53.48336, ...  \n",
       "1     53.164652  53.536547  POLYGON ((8.72996 53.16465, 8.72996 53.53655, ...  \n",
       "2     53.162825  53.165994  POLYGON ((8.72708 53.16282, 8.72708 53.16599, ...  \n",
       "3     53.164652  53.536547  POLYGON ((8.72996 53.16465, 8.72996 53.53655, ...  \n",
       "4     53.164652  53.536547  POLYGON ((8.72996 53.16465, 8.72996 53.53655, ...  \n",
       "...         ...        ...                                                ...  \n",
       "1527  53.074390  53.074390  POLYGON ((8.8062 53.07439, 8.8062 53.07439, 8....  \n",
       "1528  53.075940  53.075940  POLYGON ((8.80739 53.07594, 8.80739 53.07594, ...  \n",
       "1529  52.661410  52.661410  POLYGON ((8.25406 52.66141, 8.25406 52.66141, ...  \n",
       "1530  51.880181  51.880181  POLYGON ((8.37598 51.88018, 8.37598 51.88018, ...  \n",
       "1531  52.604420  52.604420  POLYGON ((8.37077 52.60442, 8.37077 52.60442, ...  \n",
       "\n",
       "[1532 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### STEP 5: bbox geometries\n",
    "\n",
    "# Store scrapy spider path (where outputs are stored)\n",
    "scrapy_output = \"./wikiloc_scrapy/wikiloc_scrapy/spiders/crawling_outputs/\"\n",
    "\n",
    "# Load json as df\n",
    "bremen_df = pd.read_json(scrapy_output + 'track-bremen.json')\n",
    "\n",
    "# Create column for xmin & xmax (lowest & highest longitude)\n",
    "bremen_df[\"xmin\"] = [min(x) for x in bremen_df.longitudes]\n",
    "bremen_df[\"xmax\"] = [max(x) for x in bremen_df.longitudes]\n",
    "\n",
    "# Create column for ymin & ymax (lowest & highest latitude)\n",
    "bremen_df[\"ymin\"] = [min(x) for x in bremen_df.latitudes]\n",
    "bremen_df[\"ymax\"] = [max(x) for x in bremen_df.latitudes]\n",
    "\n",
    "# Run shapely box function using new columns\n",
    "# .apply(lambda row: ..., axis=1) runs the code after the : for each row in the df\n",
    "# lambda simply indicates a function without a name is being used\n",
    "bremen_df[\"geometry\"] = bremen_df.apply(lambda row: box(row[\"xmin\"], row[\"ymin\"], \n",
    "                                                         row[\"xmax\"], row[\"ymax\"]), axis=1)\n",
    "\n",
    "# Convert the df to a gdf\n",
    "bremen_gdf = gpd.GeoDataFrame(bremen_df, geometry='geometry')\n",
    "\n",
    "# Set the CRS\n",
    "bremen_gdf.crs= \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\"\n",
    "\n",
    "# Save the gdf as a shp\n",
    "# NOTE this truncates the text!!\n",
    "bremen_gdf.to_file(\"./processing/bremen.shp\", driver='ESRI Shapefile')\n",
    "\n",
    "# Check\n",
    "bremen_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Additional Filtering\n",
    "\n",
    "**FIRST**: FIX DATE RECORDED FIELD (sometimes returns null when I think there should be data - try finding an example with data so far and check out xpaths)\n",
    "\n",
    "Must do:\n",
    "- filter out crazy trails (with massive bbox)\n",
    "- figure out how to handle trails with only one set of coordinates (start location) \n",
    "- spatial filter for consensus forest and non-consensus forest\n",
    "- spatial filter for Natura 2000 areas\n",
    "\n",
    "To consider:\n",
    "- filter for 2018\n",
    "- filter certain activity types?\n",
    "- remove trails without any associated text (this depends if I end up using text or just trail counts)\n",
    "- remove trails which have a bbox area below a certain value? (loop trails without photos/waypoints = to hard to tell where exactly the trail is)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
