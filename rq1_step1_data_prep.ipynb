{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1 Data Preparation\n",
    "\n",
    "[Add description]\n",
    "\n",
    "Steps:\n",
    "1. **Manually** download all datasets (5 forest definitions and Natura 2000) \n",
    "2. Filter Natura 2000 for areas in Germany\n",
    "3. Mosaic data which comes in tiles (Hansen & JAXA)\n",
    "4. Threshold & update (Hansen)\n",
    "5. Extract layer from netcdf (ESA)\n",
    "6. Reproject to the most common projection - EPSG 3035\n",
    "7. Rasterise or Upsample (WITHOUT INTERPOLATION) to 5m \n",
    "8. Clip data to German Natura 2000 areas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup\n",
    "\n",
    "Used this for help with directory setup: \n",
    "https://www.freecodecamp.org/news/creating-a-directory-in-python-how-to-create-a-folder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ./rawdata already exists\n",
      "Folder ./processing already exists\n",
      "Folder ./outputs already exists\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import warnings\n",
    "import glob\n",
    "\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.crs import CRS \n",
    "import xarray as xr \n",
    "import rioxarray as rio\n",
    "\n",
    "# Create required directories if they don't already exist\n",
    "# Note: these directories are ignored in git\n",
    "path_list = (\"./rawdata\", \"./processing\", \"./outputs\")\n",
    "\n",
    "for path in path_list:\n",
    "  if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "    print(\"Folder %s created!\" % path)\n",
    "  else:\n",
    "    print(\"Folder %s already exists\" % path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Manually download datasets\n",
    "\n",
    "As several of the datasets require login credentials and are not available through an API, I decided to manually download all the required data. I have stored everything in the \"rawdata\" folder. This folder is set to be ignored by git because the files are too big to push onto the GitHub repo.\n",
    "\n",
    "**So for the first step: manually download all datasets using the notes below and save to the \"rawdata\" folder.** \n",
    "\n",
    "Note: For the forest definiton layers I have downloaded the 2018 datasets as this is the most recent data available across all datasets. \n",
    "\n",
    "**1. UMD (Hansen) / Global Forest Watch**\n",
    "- Download from: https://storage.googleapis.com/earthenginepartners-hansen/GFC-2023-v1.11/download.html\n",
    "    - Using the map interface, download the treecover2000, gain & lossyear layers for the 4 granules with top-left corner at: (60N, 0E), (60N, 10E), (50N, 0E) and (50N, 10E). \n",
    "    - The files will be used in combination with each other to generate a dataset that corresponds (roughly) to forest cover in 2018.\n",
    "- My info:\n",
    "    - Download date: 15 Jan 2025\n",
    "    - File: rawdata/Hansen_GFC-2023-v1.11 (folder contains 12 tifs - 4 each for cover, gain and loss)\n",
    "\n",
    "**2. ESA Land Cover**\n",
    "- Download from: https://cds.climate.copernicus.eu/datasets/satellite-land-cover?tab=download \n",
    "    - Login credentials required (there is a prompt in the page to sign up/login).\n",
    "    - Select 2018 map and v2.1.1.\n",
    "    - Only download the sub-region for ~Germany bounding box (N:56, W:1, E:16, S:46).\n",
    "- My Info:\n",
    "    - Download date: 14 Jan 2025\n",
    "    - File: rawdata/C3S-LC-L4-LCCS-Map-300m-P1Y-2018-v2.1.1.area-subset.56.1.46.16.nc\n",
    "\n",
    "**3. JAXA FNF** \n",
    "- Download from: https://www.eorc.jaxa.jp/ALOS/en/palsar_fnf/data/index.htm\n",
    "    - Login credentials required (To register, go here: https://www.eorc.jaxa.jp/ALOS/en/palsar_fnf/registration.htm).\n",
    "    - Under the heading \"PALSAR/PALSAR-2 mosaic and forest/non-forest (FNF) map\", select the 2018 data.\n",
    "    - Use the map interface to click through until you can download tiles. I opted to download four 5 x 5 tiles using the link above the map (for N55E005, N55E010, N50E005, N50E010), but also had to supplement with some individual tiles. I used QGIS to sort through the tiles and figure out which ones were needed. In total, 73 tiles are needed for the Germany Natura areas - a list of the required tile names is available in: other/jaxa_tile_list.txt\n",
    "- My Info:\n",
    "    - Download date: 15 Jan 2025\n",
    "    - File: rawdata/jaxa_2018_fnf_ger (folder contains 73 tifs)  \n",
    "\n",
    "**4. CORINE Land Use** \n",
    "- Download from: https://land.copernicus.eu/en/products/corine-land-cover/clc2018#download\n",
    "    - Login credentials required (there is a prompt in the page to sign up/login).\n",
    "    - Click on “Go to download by area”. Then select the CORINE land cover 2018 layer, use the area selection tool to click on Germany and then click on the download icon beside the layer name. \n",
    "    - From the cart, select the dataset and chose \"vector\" and \"shapefile\". I opted for vector so that I can rasterise at a common resolution that makes sense with the other data. Click the \"Process Download Request\" button.\n",
    "    - NOTE: At this point the download request enters a queue which can take a long time. When it is ready to download, an email will be sent so you don't have to keep checking it.\n",
    "- My Info:\n",
    "    - Download date: 16 Jan 2025 (request date - ready for download on 18 Jan 2025)\n",
    "    - File: U2018_CLC2018_V2020_20u1.zip  (contains: 1 shp & its components)\n",
    "\n",
    "**5. German Land Use**\n",
    "- Download from: https://gdz.bkg.bund.de/index.php/default/corine-land-cover-5-ha-stand-2018-clc5-2018.html  \n",
    "    - Click on the “Direktdownload” tab, and then click on \"Georeferenzierung: UTM32s, Format: Shape (ZIP, 1,24 GB)\". This will download 5 shapefiles which represent the 5 main land cover classes (also used in CORINE) - individual features within these files have their more precise class as an attribute. Class 3 contains the classes related to forests, but other classes may be required for producing the FAO map (so all 5 are retained for now).\n",
    "- My Info:\n",
    "    - Download date: 14 Jan 2025\n",
    "    - File: rawdata/clc5_classXxx.zip (contains: 5 shp & their components)\n",
    "\n",
    "**6. Natura 2000 protected areas**\n",
    "- Download from: https://www.eea.europa.eu/en/datahub/datahubitem-view/6fc8ad2d-195d-40f4-bdec-576e7d1268e4\n",
    "    - Download the most recent date available (in my case: 2022 - direct link: https://sdi.eea.europa.eu/data/95e717d4-81dc-415d-a8f0-fecdf7e686b0).\n",
    "- My Info:\n",
    "    - Download date: 15 Jan 2025\n",
    "    - File: rawdata/Natura2000_end2022_epsg3035.zip (contains: 1 shp & its components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Filter Natura 2000 \n",
    "\n",
    "Use the attributes of the Natura shapefile to filter the \"MS\" field (i.e. \"Member States\") to only include \"DE\" (i.e. Germany). \n",
    "\n",
    "I also save the results as a shapefile in the outputs folder as this maybe be useful for visualisations at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Natura 2000 shapefile as a geodataframe\n",
    "# You can do this directly from the zipped file\n",
    "natura_gdf = gpd.read_file(\"rawdata/Natura2000_end2022_epsg3035.zip\")\n",
    "\n",
    "#print(natura_gdf[1:20])\n",
    "\n",
    "# Extract only the German areas\n",
    "natura_de_gdf = natura_gdf.loc[natura_gdf[\"MS\"] == \"DE\"]\n",
    "\n",
    "# Check - there should be 5200 areas\n",
    "natura_de_gdf.count()\n",
    "\n",
    "# Save the file to outputs folder (turned off warnings which is about a datetime column)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    natura_de_gdf.to_file('outputs/natura_de.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Mosaic tiled data\n",
    "\n",
    "JAXA and Hansen\n",
    "\n",
    "Help with mosaicing using rasterio: https://automating-gis-processes.github.io/CSC18/lessons/L6/raster-mosaic.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store paths for tiles in list\n",
    "jaxa_paths = glob.glob('./rawdata/jaxa_2018_fnf_ger/*.tif')\n",
    "hansen_cover_paths = glob.glob('./rawdata/Hansen_GFC-2023-v1.11/Hansen_GFC-2023-v1.11_tree*.tif')\n",
    "hansen_gain_paths = glob.glob('./rawdata/Hansen_GFC-2023-v1.11/Hansen_GFC-2023-v1.11_gain*.tif')\n",
    "hansen_loss_paths = glob.glob('./rawdata/Hansen_GFC-2023-v1.11/Hansen_GFC-2023-v1.11_loss*.tif')\n",
    "\n",
    "# Store the path for the output mosaics\n",
    "jaxa_mosaic = \"./processing/jaxa_FNF_4326_DE.tif\"\n",
    "hansen_cover_mosaic = \"./processing/hansen_treecover2000_4326_DE.tif\"\n",
    "hansen_gain_mosaic = \"./processing/hansen_gain_4326_DE.tif\"\n",
    "hansen_loss_mosaic = \"./processing/hansen_lossyear_4326_DE.tif\"\n",
    "\n",
    "# Create a function which mosaics the tiles\n",
    "def mosaic_rasters(input_paths, output_path):\n",
    "    # Create an empty list to store the opened tiles\n",
    "    tiles_to_mosaic = []\n",
    "    # Iterate through the tile paths to open them and store the opened tiles a list\n",
    "    for path in input_paths:\n",
    "        tile = rasterio.open(path)\n",
    "        tiles_to_mosaic.append(tile)\n",
    "    # Create the mosaic and store the transform information\n",
    "    mosaic, transform = merge(tiles_to_mosaic)\n",
    "    # Copy the metadata for the mosaic from a tile\n",
    "    mosaic_meta = tile.meta.copy()\n",
    "    # Update the metadata with the new information for the mosaic\n",
    "    mosaic_meta.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": mosaic.shape[1],\n",
    "                        \"width\": mosaic.shape[2],\n",
    "                        \"transform\": transform,\n",
    "                        # crs is not included, as it is copied from the tiles\n",
    "                        }\n",
    "                        )\n",
    "        # Write the mosaic with its metata to a tif file\n",
    "    with rasterio.open(output_path, \"w\", **mosaic_meta, compress=\"LZW\") as dest:\n",
    "        dest.write(mosaic)\n",
    "\n",
    "# Run the function to mosaic the tiles\n",
    "# If mosaic already exists, make sure it's not open in QGIS :) you'll get permission error if so!\n",
    "mosaic_rasters(jaxa_paths, jaxa_mosaic)\n",
    "mosaic_rasters(hansen_cover_paths, hansen_cover_mosaic)\n",
    "mosaic_rasters(hansen_gain_paths, hansen_gain_mosaic)\n",
    "mosaic_rasters(hansen_loss_paths, hansen_loss_mosaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Threshold & update for gain/loss \n",
    "\n",
    "Hansen data only\n",
    "\n",
    ">60% cover - provides a good range with the other datasets (which are lower), and it's also the threshold used by the International Geosphere-Biosphere Programme (IGBP) definition\n",
    "\n",
    "reclassify 1-100 values so that 61-100 are forest, everything else is non-forest\n",
    "\n",
    "reclassify loss so that 1-18 has a value of 1, everything else is 0\n",
    "\n",
    "subtract/add loss and gain from treecover layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Extract layer from netcdf\n",
    "\n",
    "This is required for the ESA dataset only. The netcdf file includes several different layers of information - the one I want to use is called \"lccs_class\". The aim here is to simply extract the single layer and save it as a geotiff.\n",
    "\n",
    "Help with saving netcdf layer as geotiff: https://help.marine.copernicus.eu/en/articles/5029956-how-to-convert-netcdf-to-geotiff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the ESA netcdf for conversion\n",
    "esa_netcdf = xr.open_dataset(\"./rawdata/C3S-LC-L4-LCCS-Map-300m-P1Y-2018-v2.1.1.area-subset.56.1.46.16.nc\", engine=\"netcdf4\")\n",
    "#esa_netcdf\n",
    "\n",
    "# Extract the lccs_class variable\n",
    "esa_lccs_class = esa_netcdf['lccs_class']\n",
    "\n",
    "# Provide spatial axis & define the CRS\n",
    "esa_lccs_class = esa_lccs_class.rio.set_spatial_dims(x_dim='lon', y_dim='lat')\n",
    "esa_lccs_class.rio.crs\n",
    "esa_lccs_class.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "# Save the geotiff\n",
    "esa_lccs_class.rio.to_raster(r\"./processing/esa_lccs_class_4326.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Reproject\n",
    "\n",
    "The data needed to be projected to work in units of meters for calculating area. Three datasets are not in a projected CRS (they are WGS 1984 / EPSG:4326). The most common projection is ETRS89-extended / LAEA Europe (EPSG: 3035) which is used by the Natura 2000 areas and the CORINE dataset. \n",
    "\n",
    "So for this step, all datasets which are not already in this projection, will be (re)projected to 3035.\n",
    "\n",
    "Help with reprojecting using rioxarray: https://www.earthdatascience.org/courses/use-data-open-source-python/intro-raster-data-python/raster-data-processing/reproject-raster/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test reprojecting with JAXA (NOTE: need to use rio.open_rasterio() here!)\n",
    "jaxa_4326 = rio.open_rasterio(\"./processing/jaxa_FNF_4326_DE.tif\")\n",
    "\n",
    "\n",
    "jaxa_3035 = jaxa_4326.rio.reproject(\"EPSG:3035\")\n",
    "\n",
    "jaxa_3035.rio.to_raster(r\"./processing/jaxa_3035.tif\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Rasterise or Upsample\n",
    "\n",
    "WITHOUT INTERPOLATION\n",
    "\n",
    "5m was selected as is the commonly divisible unit across all datasets; so all pixels can be approximately divided by 5, meaning there is as little transformation as possible. It also means that a lot of the detail of the shapefiles can be retained during rasterisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for German LULC:\n",
    "# convert CLC18 column to integer value and then:\n",
    "\n",
    "# gdal_rasterize -l clc5_class3xx -a clc18_int -tr 5.0 5.0 -a_nodata 0.0 -ot Float32 -of GTiff C:/Users/ninam/Documents/UZH/04_Thesis/code/qgis_comparison/clc5_classXxx/clc5_class3xx.shp C:/Users/ninam/Documents/UZH/04_Thesis/code/qgis_comparison/clc5_class3xx_raster_test_50m.tif\n",
    "\n",
    "# something similar in rasterio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Clip to German Natura areas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
