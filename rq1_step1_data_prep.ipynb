{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1 Data Preparation\n",
    "\n",
    "[Add description]\n",
    "\n",
    "Steps:\n",
    "1. **Manually** download all datasets (5 forest definitions and Natura 2000) \n",
    "2. Filter Natura 2000 for areas in Germany\n",
    "3. Mosaic data which comes in tiles (Hansen & JAXA)\n",
    "4. Threshold & update (Hansen)\n",
    "5. Extract layer from netcdf (ESA)\n",
    "6. Reproject to the most common projection - EPSG 3035\n",
    "7. Rasterise or Upsample (WITHOUT INTERPOLATION) to 5m \n",
    "8. Clip data to German Natura 2000 areas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup\n",
    "\n",
    "Used this for help with directory setup: \n",
    "https://www.freecodecamp.org/news/creating-a-directory-in-python-how-to-create-a-folder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ./rawdata already exists\n",
      "Folder ./processing already exists\n",
      "Folder ./outputs already exists\n"
     ]
    }
   ],
   "source": [
    "# SETUP\n",
    "\n",
    "# Import packages\n",
    "import os\n",
    "import warnings\n",
    "import glob\n",
    "import math\n",
    "\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.crs import CRS \n",
    "import xarray as xr \n",
    "import rioxarray as rio\n",
    "\n",
    "from osgeo import gdal \n",
    "\n",
    "# Create required directories if they don't already exist\n",
    "# Note: these directories are ignored in git\n",
    "path_list = (\"./rawdata\", \"./processing\", \"./outputs\")\n",
    "\n",
    "for path in path_list:\n",
    "  if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "    print(\"Folder %s created!\" % path)\n",
    "  else:\n",
    "    print(\"Folder %s already exists\" % path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Manually download datasets\n",
    "\n",
    "As several of the datasets require login credentials and are not available through an API, I decided to manually download all the required data. I have stored everything in the \"rawdata\" folder. This folder is set to be ignored by git because the files are too big to push onto the GitHub repo.\n",
    "\n",
    "**So for the first step: manually download all datasets using the notes below and save to the \"rawdata\" folder.** \n",
    "\n",
    "Note: For the forest definiton layers I have downloaded the 2018 datasets as this is the most recent data available across all datasets. \n",
    "\n",
    "**1. UMD (Hansen) / Global Forest Watch**\n",
    "- Download from: https://storage.googleapis.com/earthenginepartners-hansen/GFC-2023-v1.11/download.html\n",
    "    - Using the map interface, download the treecover2000, gain & lossyear layers for the 4 granules with top-left corner at: (60N, 0E), (60N, 10E), (50N, 0E) and (50N, 10E). \n",
    "    - The files will be used in combination with each other to generate a dataset that corresponds (roughly) to forest cover in 2018.\n",
    "- My info:\n",
    "    - Download date: 15 Jan 2025\n",
    "    - File: rawdata/Hansen_GFC-2023-v1.11 (folder contains 12 tifs - 4 each for cover, gain and loss)\n",
    "\n",
    "**2. ESA Land Cover**\n",
    "- Download from: https://cds.climate.copernicus.eu/datasets/satellite-land-cover?tab=download \n",
    "    - Login credentials required (there is a prompt in the page to sign up/login).\n",
    "    - Select 2018 map and v2.1.1.\n",
    "    - Only download the sub-region for ~Germany bounding box (N:56, W:1, E:16, S:46).\n",
    "- My Info:\n",
    "    - Download date: 14 Jan 2025\n",
    "    - File: rawdata/C3S-LC-L4-LCCS-Map-300m-P1Y-2018-v2.1.1.area-subset.56.1.46.16.nc\n",
    "\n",
    "**3. JAXA FNF** \n",
    "- Download from: https://www.eorc.jaxa.jp/ALOS/en/palsar_fnf/data/index.htm\n",
    "    - Login credentials required (To register, go here: https://www.eorc.jaxa.jp/ALOS/en/palsar_fnf/registration.htm).\n",
    "    - Under the heading \"PALSAR/PALSAR-2 mosaic and forest/non-forest (FNF) map\", select the 2018 data.\n",
    "    - Use the map interface to click through until you can download tiles. I opted to download four 5 x 5 tiles using the link above the map (for N55E005, N55E010, N50E005, N50E010), but also had to supplement with some individual tiles. I used QGIS to sort through the tiles and figure out which ones were needed. In total, 73 tiles are needed for the Germany Natura areas - a list of the required tile names is available in: other/jaxa_tile_list.txt\n",
    "- My Info:\n",
    "    - Download date: 15 Jan 2025\n",
    "    - File: rawdata/jaxa_2018_fnf_ger (folder contains 73 tifs)  \n",
    "\n",
    "**4. CORINE Land Use** \n",
    "- Download from: https://land.copernicus.eu/en/products/corine-land-cover/clc2018#download\n",
    "    - Login credentials required (there is a prompt in the page to sign up/login).\n",
    "    - Click on “Go to download by area”. Then select the CORINE land cover 2018 layer, use the area selection tool to click on Germany and then click on the download icon beside the layer name. \n",
    "    - From the cart, select the dataset and chose \"vector\" and \"shapefile\". I opted for vector so that I can rasterise at a common resolution that makes sense with the other data. Click the \"Process Download Request\" button.\n",
    "    - NOTE: At this point the download request enters a queue which can take a long time. When it is ready to download, an email will be sent so you don't have to keep checking it.\n",
    "- My Info:\n",
    "    - Download date: 16 Jan 2025 (request date - ready for download on 18 Jan 2025)\n",
    "    - File: U2018_CLC2018_V2020_20u1.zip  (contains: 1 shp & its components)\n",
    "\n",
    "**5. German Land Use**\n",
    "- Download from: https://gdz.bkg.bund.de/index.php/default/corine-land-cover-5-ha-stand-2018-clc5-2018.html  \n",
    "    - Click on the “Direktdownload” tab, and then click on \"Georeferenzierung: UTM32s, Format: Shape (ZIP, 1,24 GB)\". This will download 5 shapefiles which represent the 5 main land cover classes (also used in CORINE) - individual features within these files have their more precise class as an attribute. Class 3 contains the classes related to forests, but other classes may be required for producing the FAO map (so all 5 are retained for now).\n",
    "- My Info:\n",
    "    - Download date: 14 Jan 2025\n",
    "    - Files: rawdata/clc5_class1xx.zip, rawdata/clc5_class2xx.zip, rawdata/clc5_class3xx.zip, rawdata/clc5_class4xx.zip, rawdata/clc5_class5xx.zip (each contains: 1 shp & its components)\n",
    "\n",
    "**6. Natura 2000 protected areas**\n",
    "- Download from: https://www.eea.europa.eu/en/datahub/datahubitem-view/6fc8ad2d-195d-40f4-bdec-576e7d1268e4\n",
    "    - Download the most recent date available (in my case: 2022 - direct link: https://sdi.eea.europa.eu/data/95e717d4-81dc-415d-a8f0-fecdf7e686b0).\n",
    "- My Info:\n",
    "    - Download date: 15 Jan 2025\n",
    "    - File: rawdata/Natura2000_end2022_epsg3035.zip (contains: 1 shp & its components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Filter Natura 2000 \n",
    "\n",
    "Use the attributes of the Natura shapefile to filter the \"MS\" field (i.e. \"Member States\") to only include \"DE\" (i.e. Germany). \n",
    "\n",
    "I also save the results as a shapefile in the outputs folder as this maybe be useful for visualisations at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ninam\\Documents\\UZH\\04_Thesis\\code\\nm_forest_thesis\\thesis_env_conda\\Lib\\site-packages\\pyogrio\\core.py:35: RuntimeWarning: Could not detect GDAL data files.  Set GDAL_DATA environment variable to the correct path.\n",
      "  _init_gdal_data()\n"
     ]
    }
   ],
   "source": [
    "# FILTER NATURA2000\n",
    "\n",
    "# Load the Natura 2000 shapefile as a geodataframe\n",
    "# You can do this directly from the zipped file\n",
    "natura_gdf = gpd.read_file(\"./rawdata/Natura2000_end2022_epsg3035.zip\")\n",
    "\n",
    "#print(natura_gdf[1:20])\n",
    "\n",
    "# Extract only the German areas\n",
    "natura_de_gdf = natura_gdf.loc[natura_gdf[\"MS\"] == \"DE\"]\n",
    "\n",
    "# Check - there should be 5200 areas\n",
    "natura_de_gdf.count()\n",
    "\n",
    "# Save the file to outputs folder (turned off warnings which is about a datetime column)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    natura_de_gdf.to_file('./outputs/natura_DE.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Mosaic tiled data\n",
    "\n",
    "JAXA and Hansen\n",
    "\n",
    "Help with mosaicing using rasterio: https://automating-gis-processes.github.io/CSC18/lessons/L6/raster-mosaic.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOSAIC TILES\n",
    "\n",
    "# Store paths for tiles in list\n",
    "jaxa_paths = glob.glob('./rawdata/jaxa_2018_fnf_ger/*.tif')\n",
    "hansen_cover_paths = glob.glob('./rawdata/Hansen_GFC-2023-v1.11/Hansen_GFC-2023-v1.11_tree*.tif')\n",
    "hansen_gain_paths = glob.glob('./rawdata/Hansen_GFC-2023-v1.11/Hansen_GFC-2023-v1.11_gain*.tif')\n",
    "hansen_loss_paths = glob.glob('./rawdata/Hansen_GFC-2023-v1.11/Hansen_GFC-2023-v1.11_loss*.tif')\n",
    "\n",
    "# Store the path for the output mosaics\n",
    "jaxa_mosaic = \"./processing/jaxa_FNF_4326_DE.tif\"\n",
    "hansen_cover_mosaic = \"./processing/hansen_treecover2000_4326_DE.tif\"\n",
    "hansen_gain_mosaic = \"./processing/hansen_gain_4326_DE.tif\"\n",
    "hansen_loss_mosaic = \"./processing/hansen_lossyear_4326_DE.tif\"\n",
    "\n",
    "# Create a function which mosaics the tiles\n",
    "def mosaic_rasters(input_paths, output_path):\n",
    "    # Create an empty list to store the opened tiles\n",
    "    tiles_to_mosaic = []\n",
    "    # Iterate through the tile paths to open them and store the opened tiles a list\n",
    "    for path in input_paths:\n",
    "        tile = rasterio.open(path)\n",
    "        tiles_to_mosaic.append(tile)\n",
    "    # Create the mosaic and store the transform information\n",
    "    mosaic, transform = merge(tiles_to_mosaic)\n",
    "    # Copy the metadata for the mosaic from a tile\n",
    "    mosaic_meta = tile.meta.copy()\n",
    "    # Update the metadata with the new information for the mosaic\n",
    "    mosaic_meta.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": mosaic.shape[1],\n",
    "                        \"width\": mosaic.shape[2],\n",
    "                        \"transform\": transform,\n",
    "                        # crs is not included, as it is copied from the tiles\n",
    "                        }\n",
    "                        )\n",
    "        # Write the mosaic with its metata to a tif file\n",
    "    with rasterio.open(output_path, \"w\", **mosaic_meta, compress=\"LZW\") as dest:\n",
    "        dest.write(mosaic)\n",
    "\n",
    "# Run the function to mosaic the tiles\n",
    "# If mosaic already exists, make sure it's not open in QGIS :) you'll get permission error if so!\n",
    "mosaic_rasters(jaxa_paths, jaxa_mosaic)\n",
    "mosaic_rasters(hansen_cover_paths, hansen_cover_mosaic)\n",
    "mosaic_rasters(hansen_gain_paths, hansen_gain_mosaic)\n",
    "mosaic_rasters(hansen_loss_paths, hansen_loss_mosaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Threshold & update for gain/loss \n",
    "\n",
    "Hansen data only\n",
    "\n",
    ">60% cover - provides a good range with the other datasets (which are lower), and it's also the threshold used by the International Geosphere-Biosphere Programme (IGBP) definition\n",
    "\n",
    "reclassify 1-100 values so that 61-100 are forest, everything else is non-forest\n",
    "\n",
    "reclassify loss so that 1-18 has a value of 1, everything else is 0\n",
    "\n",
    "subtract/add loss and gain from treecover layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Extract layer from netcdf\n",
    "\n",
    "This is required for the ESA dataset only. The netcdf file includes several different layers of information - the one I want to use is called \"lccs_class\". The aim here is to simply extract the single layer and save it as a geotiff.\n",
    "\n",
    "Help with saving netcdf layer as geotiff: https://help.marine.copernicus.eu/en/articles/5029956-how-to-convert-netcdf-to-geotiff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT & CONVERT NETCDF DATA\n",
    "\n",
    "# Open the ESA netcdf for conversion\n",
    "esa_netcdf = xr.open_dataset(\"./rawdata/C3S-LC-L4-LCCS-Map-300m-P1Y-2018-v2.1.1.area-subset.56.1.46.16.nc\", engine=\"netcdf4\")\n",
    "#esa_netcdf\n",
    "\n",
    "# Extract the lccs_class variable\n",
    "esa_lccs_class = esa_netcdf['lccs_class']\n",
    "\n",
    "# Provide spatial axis & define the CRS\n",
    "esa_lccs_class = esa_lccs_class.rio.set_spatial_dims(x_dim='lon', y_dim='lat')\n",
    "esa_lccs_class.rio.crs\n",
    "esa_lccs_class.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "# Save the geotiff\n",
    "esa_lccs_class.rio.to_raster(\"./processing/esa_lccs_class_4326_DE.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Reproject\n",
    "\n",
    "The data needed to be projected to work in units of meters for calculating area. Three datasets are not in a projected CRS (they are WGS 1984 / EPSG:4326). The most common projection is ETRS89-extended / LAEA Europe (EPSG: 3035) which is used by the Natura 2000 areas and the CORINE dataset. \n",
    "\n",
    "So for this step, all datasets which are not already in this projection, will be (re)projected to 3035.\n",
    "\n",
    "Help with reprojecting using rioxarray: https://www.earthdatascience.org/courses/use-data-open-source-python/intro-raster-data-python/raster-data-processing/reproject-raster/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPROJECT RASTERS\n",
    "\n",
    "# A quick function for reprojecting individual rasters to EPSG:3035\n",
    "def reproject_raster_3035(input_path, output_path):\n",
    "    # Open the raster (NOTE: need to use rio.open_rasterio() here!)\n",
    "    input = rio.open_rasterio(input_path)\n",
    "    # Run the reprojection\n",
    "    output = input.rio.reproject(\"EPSG:3035\")\n",
    "    # Write the reprojected output raster\n",
    "    output.rio.to_raster(output_path, compress = \"LZW\")\n",
    "\n",
    "# Run this per file \n",
    "reproject_raster_3035(\"./processing/jaxa_FNF_4326_DE.tif\", \"./processing/jaxa_FNF_3035_DE.tif\")\n",
    "reproject_raster_3035(\"./processing/esa_lccs_class_4326_DE.tif\", \"./processing/esa_lccs_class_3035_DE.tif\")\n",
    "\n",
    "# TO DO: HANSEN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPROJECT SHPS\n",
    "\n",
    "# Store paths for shp zips in list\n",
    "ger_lulc_paths = glob.glob('./rawdata/clc5_class*.zip')\n",
    "\n",
    "# Create a function which reprojects the shp to 3035 (and saves to processing folder)\n",
    "def reproj_shp_3035(input_paths):\n",
    "    # Iterate through the shp paths \n",
    "    for path in input_paths:\n",
    "        # Open the shp for each path (excludes extra cols as they cause problems & are not needed)\n",
    "        shp = gpd.read_file(path, columns = [\"CLC18\"])\n",
    "        # Reprojects to 3035\n",
    "        shp_3035  = shp.to_crs(\"EPSG:3035\")\n",
    "\n",
    "        # For output file naming: extract the input file name (with extension)\n",
    "        name_w_ext = os.path.split(path)[1] \n",
    "        # For output file naming: remove extension from input file name \n",
    "        name_wo_ext = os.path.splitext(name_w_ext)[0]\n",
    "        # For output file naming: create the new name for reprojected shp\n",
    "        new_name = name_wo_ext + \"_3035_DE.shp\"\n",
    "\n",
    "        # Write the reprojected shp to the processing folder\n",
    "        shp_3035.to_file('./processing/' + new_name)\n",
    "\n",
    "# Run the function for the German LULC zipped shps\n",
    "reproj_shp_3035(ger_lulc_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN UP\n",
    "\n",
    "# Create a list of the data paths for deletion (files with \"4326\" in their name)\n",
    "old_data =  glob.glob('./processing/*4326*')\n",
    "\n",
    "# Create a function which deletes the input paths\n",
    "def clean_up(input_paths):\n",
    "    for path in input_paths:\n",
    "        # Check that the paths exist\n",
    "        if os.path.exists(path):  \n",
    "           os.remove(path)\n",
    "        else:\n",
    "            print(\"Nothing to clean!\") \n",
    "\n",
    "# Run the function to remove any data with \"4326\" in the file name\n",
    "clean_up(old_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Rasterise or Upsample\n",
    "\n",
    "In this step, I rasterise the vector files (German LULC - Class 3 only & CORINE) and upsample the already exisiting rasters to 5m. 5m was selected as is the commonly divisible unit across all datasets; so all pixels can be approximately divided by 5, meaning there is as little transformation as possible. It also means that a lot of the detail of the shapefiles can be retained during rasterisation. Importantly, the upsampling needs to happen WITHOUT INTERPOLATION so that no \"new\" information is created.\n",
    "\n",
    "Help for rasterising vectors: https://py.geocompx.org/05-raster-vector & https://pygis.io/docs/e_raster_rasterize.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 165. GiB for an array with shape (173477, 127979) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m ger_lulc_3_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(ger_lulc_3_test))\n\u001b[0;32m     28\u001b[0m geom_value \u001b[38;5;241m=\u001b[39m ((geom,value) \u001b[38;5;28;01mfor\u001b[39;00m geom, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ger_lulc_3_test\u001b[38;5;241m.\u001b[39mgeometry, ger_lulc_3_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m---> 30\u001b[0m rasterized \u001b[38;5;241m=\u001b[39m \u001b[43mrasterio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrasterize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeom_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mout_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mall_touched\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# background value\u001b[39;49;00m\n\u001b[0;32m     35\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ninam\\Documents\\UZH\\04_Thesis\\code\\nm_forest_thesis\\thesis_env\\Lib\\site-packages\\rasterio\\env.py:413\u001b[0m, in \u001b[0;36mensure_env.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Env\u001b[38;5;241m.\u001b[39mfrom_defaults():\n\u001b[1;32m--> 413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ninam\\Documents\\UZH\\04_Thesis\\code\\nm_forest_thesis\\thesis_env\\Lib\\site-packages\\rasterio\\features.py:380\u001b[0m, in \u001b[0;36mrasterize\u001b[1;34m(shapes, out_shape, fill, nodata, masked, out, transform, all_touched, merge_alg, default_value, dtype, skip_invalid, dst_path, dst_kwds)\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out_shape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    379\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid out_shape, must be 2D\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 380\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m     out\u001b[38;5;241m.\u001b[39mfill(fill)\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 165. GiB for an array with shape (173477, 127979) and data type int64"
     ]
    }
   ],
   "source": [
    "# RASTERISE VECTORS (WITH ATTRIBUTE VALUE)\n",
    "\n",
    "# Testing\n",
    "ger_lulc_3_test = gpd.read_file(\"./processing/clc5_class3xx_3035_DE.shp\")\n",
    "\n",
    "bounds = ger_lulc_3_test.total_bounds\n",
    "res = 5\n",
    "transform = rasterio.transform.from_origin(\n",
    "    west=bounds[0], \n",
    "    north=bounds[3], \n",
    "    xsize=res, \n",
    "    ysize=res\n",
    ")\n",
    "#transform\n",
    "\n",
    "rows = math.ceil((bounds[3] - bounds[1]) / res)\n",
    "cols = math.ceil((bounds[2] - bounds[0]) / res)\n",
    "shape = (rows, cols)\n",
    "#shape\n",
    "\n",
    "#ger_lulc_3_test_borders = ger_lulc_3_test.boundary\n",
    "#ger_lulc_3_test_borders\n",
    "\n",
    "geom = [shapes for shapes in ger_lulc_3_test.geometry]\n",
    "\n",
    "ger_lulc_3_test['id'] = range(0,len(ger_lulc_3_test))\n",
    "\n",
    "geom_value = ((geom,value) for geom, value in zip(ger_lulc_3_test.geometry, ger_lulc_3_test['id']))\n",
    "\n",
    "rasterized = rasterio.features.rasterize(geom_value,\n",
    "                                out_shape = shape,\n",
    "                                transform = transform,\n",
    "                                all_touched = True,\n",
    "                                fill = -5,   # background value\n",
    "                                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rasterized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m shape\n\u001b[0;32m      7\u001b[0m ger_lulc_3_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 9\u001b[0m \u001b[43mrasterized\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rasterized' is not defined"
     ]
    }
   ],
   "source": [
    "with rasterio.open(\n",
    "        \"./processing/rasterized_vector_test.tif\", \"w\",\n",
    "        driver = \"GTiff\",\n",
    "        transform = transform,\n",
    "        width = rasterized.shape[1], # or shape[0]?\n",
    "        height = rasterized.shape[2], # or shape [1]?\n",
    "        compress=\"LZW\") as dst:\n",
    "    dst.write(rasterized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for German LULC:\n",
    "# convert CLC18 column to integer value and then:\n",
    "\n",
    "# gdal_rasterize -l clc5_class3xx -a clc18_int -tr 5.0 5.0 -a_nodata 0.0 -ot Float32 -of GTiff C:/Users/ninam/Documents/UZH/04_Thesis/code/qgis_comparison/clc5_classXxx/clc5_class3xx.shp C:/Users/ninam/Documents/UZH/04_Thesis/code/qgis_comparison/clc5_class3xx_raster_test_50m.tif\n",
    "\n",
    "# something similar in rasterio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Clip to German Natura areas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
